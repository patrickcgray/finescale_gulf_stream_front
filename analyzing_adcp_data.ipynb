{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing ADCP Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling in a multiple years of ADCP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "import hvplot.xarray\n",
    "\n",
    "\n",
    "import cartopy.crs as crs\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import hvplot.pandas  # noqa\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import scipy.io\n",
    "\n",
    "import scipy.signal\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pull in GOES data for this full two year period via\n",
    "\n",
    "http://coastwatch.pfeg.noaa.gov/erddap/griddap/jplStarG16SSTv270.nc?sea_surface_temperature%5B(2020-09-01):1:(2022-04-15T13:00:00Z)%5D%5B(37.5):1:(34.2)%5D%5B(-76.6):1:(-72.99)%5D\n",
    "\n",
    "Had to split it into two downloads to finish without error:\n",
    "\n",
    "http://coastwatch.pfeg.noaa.gov/erddap/griddap/jplStarG16SSTv270.nc?sea_surface_temperature%5B(2020-09-01):1:(2021-06-15T13:00:00Z)%5D%5B(37.5):1:(34.2)%5D%5B(-76.6):1:(-72.99)%5D\n",
    "\n",
    "http://coastwatch.pfeg.noaa.gov/erddap/griddap/jplStarG16SSTv270.nc?sea_surface_temperature%5B(2021-06-15T14:00:00Z):1:(2022-04-15T13:00:00Z)%5D%5B(37.5):1:(34.2)%5D%5B(-76.6):1:(-72.99)%5D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this finall worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.nodc:GHRSST-ABI_G16-STAR-L3C\n",
    "\n",
    "https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplStarG16SSTv270.nc?sea_surface_temperature%5B(2020-09-01):1:(2021-01-01T13:00:00Z)%5D%5B(37.5):1:(34.2)%5D%5B(-76.6):1:(-72.99)%5D\n",
    "\n",
    "https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplStarG16SSTv270.nc?sea_surface_temperature%5B(2021-01-01T13:00:00Z):1:(2021-04-01T13:00:00Z)%5D%5B(37.5):1:(34.2)%5D%5B(-76.6):1:(-72.99)%5D\n",
    "\n",
    "https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplStarG16SSTv270.nc?sea_surface_temperature%5B(2021-04-01):1:(2021-07-15)%5D%5B(37.5):1:(34.2)%5D%5B(-76.6):1:(-72.99)%5D\n",
    "\n",
    "https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplStarG16SSTv270.nc?sea_surface_temperature%5B(2021-07-15):1:(2021-10-15)%5D%5B(37.5):1:(34.2)%5D%5B(-76.6):1:(-72.99)%5D\n",
    "\n",
    "https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplStarG16SSTv270.nc?sea_surface_temperature%5B(2021-10-15):1:(2022-01-01)%5D%5B(37.5):1:(34.2)%5D%5B(-76.6):1:(-72.99)%5D\n",
    "\n",
    "https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplStarG16SSTv270.nc?sea_surface_temperature%5B(2022-01-15):1:(2022-03-15)%5D%5B(37.5):1:(34.2)%5D%5B(-76.6):1:(-72.99)%5D\n",
    "\n",
    "https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplStarG16SSTv270.nc?sea_surface_temperature%5B(2022-03-15):1:(2022-05-15)%5D%5B(37.5):1:(34.2)%5D%5B(-76.6):1:(-72.99)%5D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = glob.glob('data/all_goes/*.nc')\n",
    "goes_ds = xr.open_dataset(fns[0])\n",
    "\n",
    "for fn in fns[1:]:\n",
    "    new_ds = xr.open_dataset(fn)\n",
    "    goes_ds = xr.concat([goes_ds,new_ds],dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimeindex = goes_ds.indexes['time'].to_datetimeindex()  \n",
    "goes_ds['time'] = datetimeindex\n",
    "goes_ds = goes_ds.sortby('time')\n",
    "goes_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "all_files = glob.glob('data/all_adcp/processed/*.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for f in all_files:\n",
    "    files.append(f.split('100s')[0])\n",
    "filenames = list(np.unique(files))\n",
    "filenames = [f+'100s' for f in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = [datetime.strptime(f.split('_')[2][:-5], '%Y%m%dT%H%S') for f in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,7))\n",
    "ax.scatter(datetimes, range(len(datetimes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tentative_good_idxs = [4,5,6,7,8,9,10,11,12,13,16,17,20,21,22,23,26,27,28,30,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,60,61,62,63,64,65,66,67,68]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pulling in profile code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes I realize this is an ugly brute force way to do this but it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "vmp_fns = glob.glob('data/VMP/2020*.mat')\n",
    "vmp_fns.sort()\n",
    "\n",
    "names = ['t'+str(i) for i in np.arange(count,len(vmp_fns)+count)]\n",
    "count += len(vmp_fns)\n",
    "\n",
    "li = []\n",
    "for i, fn in enumerate(vmp_fns):\n",
    "    mat = scipy.io.loadmat(fn)\n",
    "    for item in list(mat.keys()):\n",
    "        if item not in ['__header__', '__version__', '__globals__']:\n",
    "            df_tmp = pd.DataFrame(data=mat[item], columns=['time', 'depth (dBars)', 'temp (C)','salinity (PSU)', 'potential density (kg/m^3 -1000)', \n",
    "                                                    'chla (ppb)', 'turbidity (FTU)', 'turb kinetic energy 1 (W/kg)', 'turb kinetic energy 2 (W/kg)'])\n",
    "            df_tmp['transect'] = names[i]\n",
    "            df_tmp['profile_num'] = names[i]+'_'+item.split('profile')[-1]\n",
    "            li.append(df_tmp)\n",
    "\n",
    "profiles_2020 = pd.concat(li, axis=0, ignore_index=True)\n",
    "profiles_2020['dt'] = pd.to_datetime('2020-1-1') + pd.to_timedelta(profiles_2020.time, unit='D') - pd.Timedelta(days=1)\n",
    "profiles_2020 = profiles_2020.set_index('dt')\n",
    "profiles_2020 = profiles_2020.sort_index(ascending=True)\n",
    "profiles_2020['datetime'] = pd.to_datetime('2020-1-1') + pd.to_timedelta(profiles_2020.time, unit='D') - pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmp_fns = glob.glob('data/VMP/YD*.mat') + glob.glob('data/VMP/Cruise1/*.mat') + glob.glob('data/VMP/Cruise2/*.mat')\n",
    "vmp_fns.sort()\n",
    "\n",
    "names = ['t'+str(i) for i in np.arange(count,len(vmp_fns)+count)]\n",
    "count += len(vmp_fns)\n",
    "\n",
    "li = []\n",
    "for i, fn in enumerate(vmp_fns):\n",
    "    mat = scipy.io.loadmat(fn)\n",
    "    for item in list(mat.keys()):\n",
    "        if item not in ['__header__', '__version__', '__globals__']:\n",
    "            df_tmp = pd.DataFrame(data=mat[item], columns=['time', 'depth (dBars)', 'temp (C)','salinity (PSU)', 'potential density (kg/m^3 -1000)', \n",
    "                                                    'chla (ppb)', 'turbidity (FTU)', 'turb kinetic energy 1 (W/kg)', 'turb kinetic energy 2 (W/kg)'])\n",
    "            df_tmp['transect'] = names[i]\n",
    "            df_tmp['profile_num'] = names[i]+'_'+item.split('profile')[-1]\n",
    "            li.append(df_tmp)\n",
    "\n",
    "profiles_2021 = pd.concat(li, axis=0, ignore_index=True)\n",
    "profiles_2021['dt'] = pd.to_datetime('2021-1-1') + pd.to_timedelta(profiles_2021.time, unit='D') - pd.Timedelta(days=1)\n",
    "profiles_2021 = profiles_2021.set_index('dt')\n",
    "profiles_2021 = profiles_2021.sort_index(ascending=True)\n",
    "profiles_2021['datetime'] = pd.to_datetime('2021-1-1') + pd.to_timedelta(profiles_2021.time, unit='D') - pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmp_fns = glob.glob('data/VMP/VMP*.mat')\n",
    "vmp_fns.sort()\n",
    "\n",
    "names = ['t'+str(i) for i in np.arange(count,len(vmp_fns)+count)]\n",
    "count += len(vmp_fns)\n",
    "\n",
    "li = []\n",
    "for i, fn in enumerate(vmp_fns):\n",
    "    mat = scipy.io.loadmat(fn)\n",
    "    for item in list(mat.keys()):\n",
    "        if item not in ['__header__', '__version__', '__globals__']:\n",
    "            df_tmp = pd.DataFrame(data=mat[item], columns=['time', 'depth (dBars)', 'temp (C)','salinity (PSU)', 'potential density (kg/m^3 -1000)', \n",
    "                                                    'chla (ppb)', 'turbidity (FTU)', 'turb kinetic energy 1 (W/kg)', 'turb kinetic energy 2 (W/kg)'])\n",
    "            df_tmp['transect'] = names[i]\n",
    "            df_tmp['profile_num'] = names[i]+'_'+item.split('profile')[-1]\n",
    "            li.append(df_tmp)\n",
    "\n",
    "profiles_2022 = pd.concat(li, axis=0, ignore_index=True)\n",
    "profiles_2022['dt'] = pd.to_datetime('2022-1-1') + pd.to_timedelta(profiles_2022.time, unit='D') - pd.Timedelta(days=1)\n",
    "profiles_2022 = profiles_2022.set_index('dt')\n",
    "profiles_2022 = profiles_2022.sort_index(ascending=True)\n",
    "profiles_2022['datetime'] = pd.to_datetime('2022-1-1') + pd.to_timedelta(profiles_2022.time, unit='D') - pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.concat([profiles_2020,profiles_2021,profiles_2022])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy import distance\n",
    "\n",
    "def get_dist(df, df_start, flip=False):\n",
    "    distances = []\n",
    "    # flip allows you to swap the starting side so that it can always do dist from the same side\n",
    "    if flip == False:\n",
    "        first_row = df_start.iloc[0]\n",
    "    else:\n",
    "        first_row = df_start.iloc[-1]\n",
    "    for row in df.itertuples(index=False):\n",
    "        distances.append(distance.distance((row.lat, row.lon),(first_row.lat,first_row.lon)).meters)\n",
    "    return(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_locs(df, adcp_df):\n",
    "    # add in lat and lon\n",
    "    lats = []\n",
    "    lons = []\n",
    "    dists = []\n",
    "    for i in range(len(df)):\n",
    "        row = adcp_df.iloc[adcp_df.index.get_loc(pd.to_datetime(df.iloc[i].datetime), method='nearest')]\n",
    "        lats.append(row.lat)\n",
    "        lons.append(row.lon)\n",
    "        dists.append(row.dist)\n",
    "    df['lat'] = lats\n",
    "    df['lon'] = lons\n",
    "    df['dist'] = dists\n",
    "\n",
    "    # now make it the same for each profile depending on the first row with that profile_num\n",
    "    profile_nums = df.profile_num.unique()\n",
    "    profile_num_idx = 0\n",
    "    \n",
    "    lats = []\n",
    "    lons = []\n",
    "    dists = []\n",
    "    for row in df.itertuples(index=False):\n",
    "#         print(profile_num_idx)\n",
    "        try:\n",
    "            if row.profile_num == profile_nums[profile_num_idx]:\n",
    "                top_lat = row.lat\n",
    "                top_lon = row.lon\n",
    "                dist = row.dist\n",
    "                profile_num_idx+=1\n",
    "        except IndexError:\n",
    "#             print('index error')\n",
    "            pass\n",
    "        lats.append(top_lat)\n",
    "        lons.append(top_lon)\n",
    "        dists.append(dist)\n",
    "        \n",
    "    df['lat'] = lats\n",
    "    df['lon'] = lons\n",
    "    df['dist'] = dists\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colour import Color\n",
    "def plot_profiles(df, adcp_df, start_time, end_time, data_variables, plot=False):\n",
    "\n",
    "#     print('##############################')\n",
    "# #     print('Transect ' + str(i+1))\n",
    "#     print('##############################')\n",
    "    df_subset = df.loc[start_time:end_time]\n",
    "    \n",
    "    df_subset = profile_locs(df_subset, adcp_df)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,4, figsize=(30,5))\n",
    "    \n",
    "    if len(df_subset) == 0:\n",
    "        print('Did not have profile data.')\n",
    "        return(ax)\n",
    "    \n",
    "    # Original data (e.g. measurements)\n",
    "    for i, data_var in enumerate(data_variables):\n",
    "        if plot:\n",
    "            cmap='RdYlBu_r'\n",
    "            norm=None\n",
    "#             fig, ax = plt.subplots(figsize=(17.2,7))\n",
    "            if data_var == 'temp (C)':\n",
    "                cmap = cmocean.cm.thermal\n",
    "#                 vmin=21\n",
    "#                 vmax=27.5\n",
    "            elif data_var == 'salinity (PSU)':\n",
    "                cmap = cmocean.cm.haline\n",
    "                pass\n",
    "#                 vmin=34.8\n",
    "#                 vmax=36.2\n",
    "            elif data_var == 'potential density (kg/m^3 -1000)':\n",
    "                cmap = cmocean.cm.dense\n",
    "#                 vmin=22.5\n",
    "#                 vmax=23.5\n",
    "            elif data_var == 'chla (ppb)':\n",
    "                vmin=0.0\n",
    "                vmax=0.6\n",
    "                cmap = cmocean.cm.algae\n",
    "            elif data_var == 'turbidity (FTU)':\n",
    "                pass\n",
    "#                 vmin=1\n",
    "#                 vmax=1.12\n",
    "            elif data_var == 'turb kinetic energy 1 (W/kg)':\n",
    "                vmin=1e-10\n",
    "                vmax=1e-6\n",
    "                norm=mat_colors.LogNorm()\n",
    "            elif data_var == 'turb kinetic energy 2 (W/kg)':\n",
    "                vmin=1e-10\n",
    "                vmax=1e-6\n",
    "                norm=mat_colors.LogNorm()\n",
    "            elif data_var == 'cluster':\n",
    "                vmin=0\n",
    "                vmax=6\n",
    "                cmap='jet'\n",
    "#                 norm=mat_colors.LogNorm()\n",
    "                \n",
    "#             flip=False\n",
    "#             if transect in [1,8]:\n",
    "#                 flip=True\n",
    "            \n",
    "#             df_subset_distances = get_dist(df_subset, adcp_df.loc[start_time:end_time], flip=False)\n",
    "\n",
    "            vmin = np.nanpercentile(df_subset[data_var], 8)\n",
    "            vmax = np.nanpercentile(df_subset[data_var], 92)\n",
    "            if data_var == 'ekbackscatter':\n",
    "                vmin=97.5\n",
    "                vmax=115\n",
    "            if data_var == 'cluster':\n",
    "                vmin=0\n",
    "                vmax=6\n",
    "            if data_var == 'salinity (PSU)':\n",
    "                vmin=35\n",
    "                vmax=36.5\n",
    "            if data_var == 'chla (ppb)':\n",
    "                vmin=0\n",
    "                vmax=0.6\n",
    "            sc = ax[i].scatter(df_subset['dist'], df_subset['depth (dBars)'],c=df_subset[data_var],cmap=cmap, s=150, alpha=.7, vmin=vmin,vmax=vmax,)# norm=norm)\n",
    "            \n",
    "#             if transect==0:\n",
    "                \n",
    "#                 Sep 05 2021 13:15:33 [System UTC, header]\n",
    "#                 Sep 05 2021 15:21:30 [System UTC, header]\n",
    "#                 Sep 05 2021 17:14:42 [System UTC, header]\n",
    "                        \n",
    "                \n",
    "#                 if data_var == 'temp (C)':\n",
    "#                     for t_string in ['Sep 05 2021 13:15:33']:\n",
    "#                         df_idx = df_subset.index.get_loc(pd.to_datetime('Sep 05 2021 13:15:33'), method='nearest')\n",
    "#                         ax.scatter(df_subset_distances, df_subset['depth (dBars)'],c=df_subset[data_var]\n",
    "            \n",
    "#             sc = ax.scatter(df_subset['datetime'], df_subset['depth (dBars)'],c=df_subset[data_var],cmap=cmap, s=150, alpha=.7, vmin=vmin,vmax=vmax, norm=norm)\n",
    "            ax[i].set_ylim(-120,0)\n",
    "#             ax.set_xlim(df_subset['datetime'].max()+timedelta(hours=.1),df_subset['datetime'].min()-timedelta(hours=.1))\n",
    "            cb = fig.colorbar(sc,ax=ax[i])\n",
    "#             cb.set_label(data_var)\n",
    "            ax[i].set_title(data_var)\n",
    "#             depths = [-5,-10,-20,-30,-60]\n",
    "        \n",
    "#             colors = list(Color(\"black\").range_to(Color(\"blue\"),len(depths)))\n",
    "#             hex_colors = [j.hex for j in colors]\n",
    "#             # integrate down to z depth\n",
    "#             ax2 = ax.twinx()\n",
    "#             for idx,z in enumerate(depths):\n",
    "#                 # cut it off at depth (dBars) >= z\n",
    "#                 df_tmp = df_subset[df_subset['depth (dBars)'] >= z] \n",
    "#                 df_tmp_grouped = df_tmp.groupby('profile_num').mean()\n",
    "#                 df_tmp_grouped['datetime'] = pd.to_datetime('2021-1-1') + pd.to_timedelta(df_tmp_grouped.time, unit='D') - pd.Timedelta(days=1)\n",
    "\n",
    "\n",
    "#                 ax2.plot(df_tmp_grouped['datetime'],df_tmp_grouped[data_var], label=str(z), color=hex_colors[idx])\n",
    "#                 ax2.set_ylim(vmin,vmax)\n",
    "#                 ax2.legend(loc='lower left',title='Depth Integrated Values')\n",
    "            \n",
    "            \n",
    "        \n",
    "            ax[i].set_ylabel('Depth (m')\n",
    "            ax[i].set_xlabel('Distance (m)')\n",
    "#             ax.set_xlim(pd.to_datetime(start_time), pd.to_datetime(end_time))\n",
    "#             ax.set_xlim(pd.to_datetime(end_time),pd.to_datetime(start_time))\n",
    "        #     ax[1].xaxis.set_major_locator(plt.MaxNLocator(7))\n",
    "#     fig.autofmt_xdate(rotation=45)\n",
    "#             ax.xaxis.set_major_locator(plt.MaxNLocator(15))\n",
    "#             print(data_var[:20]+'.png')\n",
    "#             fig.savefig('figs/sept_transect_'+str(transect+1)+'_'+data_var[:20]+'.png')\n",
    "    return(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colour import Color\n",
    "def grab_vmp_data(df, adcp_df, start_time, end_time):\n",
    "\n",
    "    df_subset = df.loc[start_time:end_time]\n",
    "    df_subset['DOY'] = df_subset.datetime.dt.day_of_year\n",
    "    df_subset.sort_index(inplace=True, ascending=True)\n",
    "    \n",
    "    df_subset = profile_locs(df_subset, adcp_df)\n",
    "    z = -4.5\n",
    "    df_tmp = df_subset[df_subset['depth (dBars)'] >= z] \n",
    "    df_tmp_grouped = df_tmp.groupby('profile_num').mean()\n",
    "    \n",
    "    df_tmp_grouped.sort_values('dist', inplace=True)\n",
    "    \n",
    "    return(df_tmp_grouped['salinity (PSU)'].values, df_tmp_grouped['temp (C)'].values, df_tmp_grouped['chla (ppb)'].values, df_tmp_grouped['turbidity (FTU)'].values, df_tmp_grouped['DOY'].values, df_tmp_grouped['dist'].values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx,fn in enumerate(filenames):\n",
    "#     if idx not in [39,40,41,42]:\n",
    "# #     if idx not in range(25,39):\n",
    "#         continue\n",
    "#     print(idx)\n",
    "#     print(fn)\n",
    "    \n",
    "# #     try:\n",
    "\n",
    "#     dist = scipy.io.loadmat(fn+'_distance.mat')['distance']\n",
    "#     sst = scipy.io.loadmat(fn+'_SST.mat')['SST']\n",
    "#     time = scipy.io.loadmat(fn+'_time.mat')['time']\n",
    "#     timestamps = pd.to_datetime(time[0,:]-719529, unit='D')\n",
    "\n",
    "# #         if idx in [5,28,39,40,41]:\n",
    "# #             dist = (dist - dist[-1])*-1\n",
    "\n",
    "#     X = scipy.io.loadmat(fn+'_X.mat')['X']\n",
    "#     Y = scipy.io.loadmat(fn+'_Y.mat')['Y']\n",
    "#     vMag = scipy.io.loadmat(fn+'_vmag.mat')['C']\n",
    "\n",
    "#     vDir = scipy.io.loadmat(fn+'_vdir.mat')['C']\n",
    "\n",
    "#     echo = scipy.io.loadmat(fn+'_echo.mat')['C']\n",
    "#     Xecho = scipy.io.loadmat(fn+'_Xecho.mat')['X']\n",
    "#     Yecho = scipy.io.loadmat(fn+'_Yecho.mat')['Y']\n",
    "#     # correcting for the smaller bin size\n",
    "#     Yecho = (Yecho*0.502)-1\n",
    "\n",
    "#     lat = scipy.io.loadmat(fn+'_lat.mat')['lat']\n",
    "#     long = scipy.io.loadmat(fn+'_long.mat')['long']\n",
    "    \n",
    "#     adcp_df = pd.DataFrame({'dt':timestamps,\n",
    "#                     'datetime':timestamps,\n",
    "#                    'lat': lat[:,0],\n",
    "#                    'lon':long[:,0],\n",
    "#                            'dist':dist[:,0]})\n",
    "\n",
    "#     adcp_df = adcp_df.set_index('dt')\n",
    "#     adcp_df = adcp_df.sort_index(ascending=True)\n",
    "\n",
    "#     plot_profiles(profiles, adcp_df, timestamps[0],timestamps[-1], ['temp (C)', 'salinity (PSU)', 'chla (ppb)'], plot=True)\n",
    "\n",
    "#     fig, ax = plt.subplots(3,1, figsize=(10,12))\n",
    "#     vMag_reshape = vMag.reshape(-1,69).T\n",
    "#     vDir_reshape = vDir.reshape(-1,69).T\n",
    "\n",
    "# #         if idx in [5,28,39,40,41]:\n",
    "# #             vMag_reshape = np.fliplr(vMag_reshape)\n",
    "# #             vDir_reshape = np.fliplr(vDir_reshape)\n",
    "\n",
    "#     x, y = np.meshgrid(X.reshape(-1,69)[:,0],Y[:69,0])    \n",
    "#     im = ax[0].pcolormesh(x,y,vMag_reshape,shading='gouraud', vmin=10,vmax=140)\n",
    "#     fig.colorbar(im,ax=ax[0])\n",
    "#     ax[0].set_title(\"Current Magnitude (cm/s)\")\n",
    "\n",
    "#     im = ax[1].pcolormesh(x,y,vDir_reshape,shading='gouraud', vmin=0,vmax=360, cmap='hsv')\n",
    "#     fig.colorbar(im,ax=ax[1])\n",
    "#     ax[1].set_title(\"Current Direction (Deg from North)\")\n",
    "\n",
    "#     vgradient = []\n",
    "\n",
    "#     N=180\n",
    "#     current_speed = np.mean(vMag_reshape[0:4,:],axis=0)\n",
    "#     current_speed_smooth = pd.Series(current_speed).rolling(window=N).mean().iloc[N-1:].values\n",
    "#     vgradient = []\n",
    "\n",
    "#     step = 1\n",
    "\n",
    "#     for i in range(len(current_speed)-N):\n",
    "#         du = current_speed_smooth[i] - current_speed_smooth[i+step]\n",
    "#         dx = dist[i] - dist[i+step]\n",
    "#         current_grad = du/dx\n",
    "#         vgradient.append(current_grad)\n",
    "\n",
    "#     dudx = scipy.signal.savgol_filter(current_speed_smooth, window_length=11, polyorder=2, deriv=1)\n",
    "\n",
    "#     ax_twin = ax[0].twinx()\n",
    "# #         ax_twin.plot(dist[15:-15-N], vgradient_smooth[15:-16], c='k', alpha=0.5)\n",
    "#     ax_twin.plot(dist[:-N+1], dudx, c='grey', ls='--')\n",
    "#     ax_twin.set_ylim(-0.6,0.6)\n",
    "\n",
    "#     ax_twin2 = ax[0].twinx()\n",
    "#     ax_twin2.plot(dist[:-N],current_speed_smooth[:-1],c='black')\n",
    "#     ax_twin2.set_ylim(0,140)\n",
    "\n",
    "#     ax_twin3 = ax[0].twinx()\n",
    "#     ax_twin3.plot(dist,sst, color='red')\n",
    "#     ax_twin3.set_ylim(25,30)\n",
    "#     # taking off the first 100 points because those are often noisy and never the front\n",
    "#     front_location = np.argmax(np.abs(dudx[100:-30]))+100\n",
    "\n",
    "#     echo_reshape = echo.reshape(-1,127).T\n",
    "# #         vDir_reshape = vDir.reshape(-1,69).T\n",
    "\n",
    "# #         if idx in [5,28,39,40,41]:\n",
    "# #             echo_reshape = np.fliplr(echo_reshape)\n",
    "\n",
    "#     x, y = np.meshgrid(Xecho.reshape(-1,127)[:,0],Yecho[:127,0])    \n",
    "\n",
    "#     im = ax[2].pcolormesh(x,y,echo_reshape,shading='gouraud', vmin=96,vmax=115, cmap='jet')\n",
    "#     fig.colorbar(im,ax=ax[2])\n",
    "#     ax[2].set_title(\"Echosounder Volume Backscatter (sV)\")\n",
    "\n",
    "#     ax_twin.yaxis.label.set_color('grey')\n",
    "#     ax_twin.spines['right'].set_position(('outward', 90))\n",
    "\n",
    "#     ax_twin2.yaxis.label.set_color('black')\n",
    "#     ax_twin2.spines['right'].set_position(('outward', 180))\n",
    "\n",
    "#     ax_twin3.yaxis.label.set_color('red')\n",
    "#     ax_twin3.spines['right'].set_position(('outward', 260))\n",
    "\n",
    "#     ax_twin.set_ylabel('current gradient')\n",
    "#     ax_twin2.set_ylabel('top 10m current speed (cm/s)')\n",
    "#     ax_twin3.set_ylabel('SST (C)')\n",
    "\n",
    "\n",
    "#     if idx == 42:\n",
    "#         for i in range(3):\n",
    "#             ax[i].set_xlim(dist.max(),0)\n",
    "#     else:\n",
    "#         for i in range(3):\n",
    "#             ax[i].set_xlim(0,dist.max())\n",
    "#     for i in range(3):\n",
    "#         ax[i].axvline(dist[front_location],color='k', ls='--')\n",
    "#         ax[i].set_ylim(-70,-2)\n",
    "#         ax[i].set_ylabel('Depth (m)')\n",
    "#         ax[i].set_xlabel('Dist from Start (m)')\n",
    "#         ax[i].axvline(dist[front_location],color='k', ls='--')\n",
    "\n",
    "#     fig.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "# #         fig.savefig('mag_dir_echo'+str(idx)+'.png',dpi=400)\n",
    "#     plt.show()\n",
    "\n",
    "#     print('--------------------------------------')\n",
    "\n",
    "# #     except Exception as e: \n",
    "# #         print(e)\n",
    "    \n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_seasonal = pd.read_csv('sst_gs_coastal.csv',names=['datetime', 'coastal_sst', 'gs_sst'], skiprows=1)\n",
    "chla_seasonal = pd.read_csv('chla_gs_coastal.csv',names=['datetime', 'coastal_chla', 'gs_chla'], skiprows=1)\n",
    "\n",
    "sst_seasonal.datetime = pd.to_datetime(sst_seasonal.datetime)\n",
    "sst_seasonal = sst_seasonal.set_index('datetime')\n",
    "\n",
    "chla_seasonal.datetime = pd.to_datetime(chla_seasonal.datetime)\n",
    "chla_seasonal = chla_seasonal.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "dates_x_sst = np.arange(1,366,1)\n",
    "\n",
    "####################\n",
    "\n",
    "sst_mean = sst_seasonal.groupby([sst_seasonal.index.month, sst_seasonal.index.day]).mean()\n",
    "sst_std = sst_seasonal.groupby([sst_seasonal.index.month, sst_seasonal.index.day]).std()\n",
    "\n",
    "ax.plot(dates_x_sst,sst_mean.gs_sst, c='blue', label='Gulf Stream')\n",
    "ax.plot(dates_x_sst,sst_mean.gs_sst+sst_std.gs_sst, c='blue', alpha=0.2)\n",
    "ax.plot(dates_x_sst,sst_mean.gs_sst-sst_std.gs_sst, c='blue', alpha=0.2)\n",
    "\n",
    "###################\n",
    "\n",
    "ax.plot(dates_x_sst,sst_mean.coastal_sst, c='green', label='Coastal')\n",
    "ax.plot(dates_x_sst,sst_mean.coastal_sst+sst_std.coastal_sst, c='green', alpha=0.2)\n",
    "ax.plot(dates_x_sst,sst_mean.coastal_sst-sst_std.coastal_sst, c='green', alpha=0.2)\n",
    "\n",
    "################3\n",
    "\n",
    "# ax.legend(loc='lower right')\n",
    "\n",
    "ax.set_ylabel('SST (C)')\n",
    "ax.set_xlabel('Day of Year')\n",
    "\n",
    "plt.savefig('gs_coastal_sst.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "chla_mean = chla_seasonal.groupby([chla_seasonal.index.month, chla_seasonal.index.day]).mean()\n",
    "chla_std = chla_seasonal.groupby([chla_seasonal.index.month, chla_seasonal.index.day]).std()\n",
    "\n",
    "str_dts = []\n",
    "for i in range(len(chla_mean.index)):\n",
    "    str_dts.append(str(chla_mean.index[i][1])+','+str(chla_mean.index[i][0]))\n",
    "    \n",
    "day_of_year_chla = [datetime.strptime(dt,\"%d,%m\").timetuple().tm_yday for dt in str_dts]\n",
    "\n",
    "dates_x_chla = day_of_year_chla\n",
    "\n",
    "####################\n",
    "\n",
    "ax.plot(dates_x_chla,chla_mean.gs_chla, c='blue', label='Gulf Stream')\n",
    "ax.plot(dates_x_chla,chla_mean.gs_chla+chla_std.gs_chla, c='blue', alpha=0.2)\n",
    "ax.plot(dates_x_chla,chla_mean.gs_chla-chla_std.gs_chla, c='blue', alpha=0.2)\n",
    "\n",
    "###################\n",
    "\n",
    "ax.plot(dates_x_chla,chla_mean.coastal_chla, c='green', label='Coastal')\n",
    "ax.plot(dates_x_chla,chla_mean.coastal_chla+chla_std.coastal_chla, c='green', alpha=0.2)\n",
    "ax.plot(dates_x_chla,chla_mean.coastal_chla-chla_std.coastal_chla, c='green', alpha=0.2)\n",
    "\n",
    "################3\n",
    "\n",
    "ax.set_ylim(0,2.75)\n",
    "\n",
    "# ax.legend()\n",
    "\n",
    "ax.set_ylabel('Chla (mg/m3)')\n",
    "ax.set_xlabel('Day of Year')\n",
    "plt.savefig('gs_coastal_chla.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll run the subpixel_contours() function which takes in an xarray DataArray and related geospatial metadata and returns a geodataframe of the contours at each time step.\n",
    "\n",
    "To do this we need to define an affine transformation for the SSH data since it doesn't exist in the dataset currently. Learn more [here](https://www.perrygeo.com/python-affine-transforms.html). The basic format of an affine transformation is (a, b, c, d, e, f):\n",
    "\n",
    "    a = width of a pixel\n",
    "    b = row rotation (typically zero)\n",
    "    c = x-coordinate of the upper-left corner of the upper-left pixel\n",
    "    d = column rotation (typically zero)\n",
    "    e = height of a pixel (typically negative)\n",
    "    f = y-coordinate of the of the upper-left corner of the upper-left pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affine import Affine\n",
    "from dea_spatial import subpixel_contours\n",
    "\n",
    "# ssh_ds = xr.open_zarr('data/aviso.zarr')\n",
    "ssh_ds = xr.open_dataset('data/dataset-duacs-nrt-global-merged-allsat-phy-l4_1660503138026.nc')\n",
    "ssh_ds.adt.attrs[\"units\"] = 'meters'\n",
    "\n",
    "ssh_affine = Affine(0.25, 0.0, -81.875-.25/2, 0.0, 0.25, 26.125-.25/2)\n",
    "# ssh_affine = Affine(0.25, 0.0, -82.12-.25/2, 0.0, 0.25, 43.62-.25/2)\n",
    "\n",
    "# this function needs all the data in memory so load it in\n",
    "ssh_ds.adt.load()\n",
    "\n",
    "front_gdf_median = subpixel_contours(ssh_ds.adt.median(dim='time', skipna=True), [0.25], crs='EPSG:4326', min_vertices=50, affine=ssh_affine, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_gdf = subpixel_contours(ssh_ds.adt, [0.25], crs='EPSG:4326', min_vertices=50, affine=ssh_affine, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_gdf['dt'] = pd.to_datetime(front_gdf.time)\n",
    "front_gdf = front_gdf.set_index('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "front_gdf.plot(ax=ax)\n",
    "front_gdf_median.plot(ax=ax,color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the salinity and temp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = []\n",
    "front_location_list = []\n",
    "sst_list = []\n",
    "current_list = []\n",
    "echo_list = []\n",
    "interp_sst_list = []\n",
    "interp_current_list = []\n",
    "interp_echo_list = []\n",
    "\n",
    "sal_front_list = []\n",
    "\n",
    "vmp_sal_list = []\n",
    "vmp_temp_list = []\n",
    "vmp_chla_list = []\n",
    "vmp_dt_list = []\n",
    "\n",
    "for idx,fn in enumerate(filenames):\n",
    "    if idx in [0,1,2,3]:\n",
    "        continue\n",
    "    try:\n",
    "        ##########\n",
    "        \n",
    "        dist = scipy.io.loadmat(fn+'_distance.mat')['distance']\n",
    "        sst = scipy.io.loadmat(fn+'_SST.mat')['SST']\n",
    "        time = scipy.io.loadmat(fn+'_time.mat')['time']\n",
    "        timestamps = pd.to_datetime(time[0,:]-719529, unit='D')\n",
    "  \n",
    "        lat = scipy.io.loadmat(fn+'_lat.mat')['lat']\n",
    "        long = scipy.io.loadmat(fn+'_long.mat')['long']\n",
    "        \n",
    "        # the distances are crazy wrong sometimes so re-calcuating the distance\n",
    "        coords_1 = (lat[0], long[0])\n",
    "        distances = []\n",
    "        for i in range(len(lat)):\n",
    "            coords_2 = (lat[i], long[i])\n",
    "            distances.append(distance.geodesic(coords_1, coords_2).meters)\n",
    "        dist = np.array(distances)       \n",
    "\n",
    "        # checking if the current point is within 500 of one that was good, assuming the first point is good\n",
    "        # then if not setting it to nan and interpolating it out\n",
    "        last_good_idx = 0\n",
    "        bad_idxs = []\n",
    "        for di,d in enumerate(dist):\n",
    "            if dist[di] - dist[last_good_idx] < 500:\n",
    "                last_good_idx = di\n",
    "            else:\n",
    "                bad_idxs.append(di)\n",
    "        dist[bad_idxs] = np.nan\n",
    "        dist = pd.Series(dist).interpolate().values\n",
    "\n",
    "        dist = dist.reshape(-1,1)\n",
    "        \n",
    "        adcp_df = pd.DataFrame({'dt':timestamps,\n",
    "                    'datetime':timestamps,\n",
    "                    'sst':sst[:,0],\n",
    "                    'lat': lat[:,0],\n",
    "                    'lon':long[:,0],\n",
    "                    'dist':dist[:,0]})\n",
    "\n",
    "        adcp_df = adcp_df.set_index('dt')\n",
    "        adcp_df = adcp_df.sort_index(ascending=True)\n",
    "        \n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        sal_vmp, temp_vmp, chla_vmp, turb_vmp, dt_vmp, dist_vmp = grab_vmp_data(profiles, adcp_df, timestamps[0],timestamps[-1])\n",
    "            \n",
    "        vmp_sal_list.append(sal_vmp)\n",
    "        vmp_temp_list.append(temp_vmp)\n",
    "        vmp_chla_list.append(chla_vmp)\n",
    "        vmp_dt_list.append(dt_vmp)\n",
    "        \n",
    "\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how many transects do we have with VMP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for trans in vmp_sal_list:\n",
    "    if len(trans) > 0:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.concatenate(vmp_sal_list), bins=80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the seasonal dependence of salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sal_list = []\n",
    "for i in vmp_sal_list:\n",
    "    if len(i) == 0:\n",
    "        continue\n",
    "    max_sal_list.append(np.percentile(i, 95))\n",
    "\n",
    "doy_list = []\n",
    "for i in vmp_dt_list:\n",
    "    if len(i) == 0:\n",
    "        continue\n",
    "    doy_list.append(np.max(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(abs(np.array(doy_list)-225),max_sal_list)\n",
    "plt.scatter(doy_list,max_sal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import leastsq\n",
    "import pylab as plt\n",
    "\n",
    "t = np.array(doy_list)\n",
    "data = np.array(max_sal_list)\n",
    "\n",
    "guess_mean = np.mean(data)\n",
    "guess_std = 3*np.std(data)/(2**0.5)/(2**0.5)\n",
    "guess_phase = 0\n",
    "guess_freq = 1/60\n",
    "guess_amp = .3\n",
    "\n",
    "# we'll use this to plot our first estimate. This might already be good enough for you\n",
    "data_first_guess = guess_amp*np.sin(guess_freq*t+guess_phase) + guess_mean\n",
    "\n",
    "# Define the function to optimize, in this case, we want to minimize the difference\n",
    "# between the actual data and our \"guessed\" parameters\n",
    "optimize_func = lambda x: x[0]*np.sin(x[1]*t+x[2]) + x[3] - data\n",
    "est_amp, est_freq, est_phase, est_mean = leastsq(optimize_func, [guess_amp, guess_freq, guess_phase, guess_mean])[0]\n",
    "\n",
    "# recreate the fitted curve using the optimized parameters\n",
    "data_fit = est_amp*np.sin(est_freq*t+est_phase) + est_mean\n",
    "\n",
    "# recreate the fitted curve using the optimized parameters\n",
    "\n",
    "fine_t = np.arange(0,max(t),0.1)\n",
    "data_fit=est_amp*np.sin(est_freq*fine_t+est_phase)+est_mean\n",
    "\n",
    "plt.plot(t, data, '.')\n",
    "plt.scatter(t, data_first_guess, label='first guess', color='red')\n",
    "plt.plot(fine_t, data_fit, label='after fitting')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_amp, 1/est_freq, est_phase, est_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the seasonal dependence of temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_temp_list = []\n",
    "for i in vmp_temp_list:\n",
    "    if len(i) == 0:\n",
    "        continue\n",
    "    max_temp_list.append(np.percentile(i, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import leastsq\n",
    "import pylab as plt\n",
    "\n",
    "t = dates_x_sst\n",
    "data = sst_mean.gs_sst-273\n",
    "\n",
    "t = np.array(doy_list)\n",
    "data = np.array(max_temp_list)\n",
    "\n",
    "\n",
    "guess_mean = np.mean(data)\n",
    "guess_std = 3*np.std(data)/(2**0.5)/(2**0.5)\n",
    "guess_phase = 230\n",
    "guess_freq = 1/60\n",
    "guess_amp = 5\n",
    "\n",
    "# we'll use this to plot our first estimate. This might already be good enough for you\n",
    "data_first_guess = guess_amp*np.sin(guess_freq*t+guess_phase) + guess_mean\n",
    "\n",
    "# Define the function to optimize, in this case, we want to minimize the difference\n",
    "# between the actual data and our \"guessed\" parameters\n",
    "optimize_func = lambda x: x[0]*np.sin(x[1]*t+x[2]) + x[3] - data\n",
    "sst_est_amp, sst_est_freq, sst_est_phase, sst_est_mean = leastsq(optimize_func, [guess_amp, guess_freq, guess_phase, guess_mean])[0]\n",
    "\n",
    "# recreate the fitted curve using the optimized parameters\n",
    "data_fit = sst_est_amp*np.sin(sst_est_freq*t+sst_est_phase) + sst_est_mean\n",
    "\n",
    "# recreate the fitted curve using the optimized parameters\n",
    "\n",
    "fine_t = np.arange(0,max(t),0.1)\n",
    "data_fit=sst_est_amp*np.sin(sst_est_freq*fine_t+sst_est_phase)+sst_est_mean\n",
    "\n",
    "plt.plot(t, data, '.')\n",
    "plt.scatter(t, data_first_guess, label='first guess')\n",
    "plt.plot(fine_t, data_fit, label='after fitting')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_est_amp, 1/sst_est_freq, sst_est_phase, sst_est_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "almost the exact same when fitting with the satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_est_amp, 1/sst_est_freq, sst_est_phase, sst_est_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_est_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doy = np.arange(0,365,1)\n",
    "def provide_gs_temp_threshold(doy,buffer=0.0):\n",
    "    temp_est = sst_est_amp*np.sin(sst_est_freq*doy+sst_est_phase) + sst_est_mean\n",
    "    return(temp_est-buffer)\n",
    "\n",
    "temp_est = provide_gs_temp_threshold(doy)\n",
    "\n",
    "plt.scatter(doy,temp_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doy = np.arange(0,365,1)\n",
    "def provide_gs_sal_threshold(doy,buffer=0.1):\n",
    "    sal_est = est_amp*np.sin(est_freq*doy+est_phase) + est_mean\n",
    "    return(sal_est-buffer)\n",
    "\n",
    "sal_est = provide_gs_sal_threshold(doy,buffer=0)\n",
    "temp_est = provide_gs_temp_threshold(doy,buffer=0)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "ax.plot(doy,sal_est, c='blue', label='salinity')\n",
    "ax.set_ylabel('Salinity (PSU)')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(doy,temp_est, c='red', label='temp')\n",
    "ax2.set_ylabel('Temp (C)')\n",
    "ax.axvline(42, c='k', ls='--')\n",
    "ax.axvline(230,c='k', ls='--')\n",
    "\n",
    "ax.scatter(np.array(doy_list),np.array(max_sal_list), c='blue')\n",
    "ax2.scatter(np.array(doy_list),np.array(max_temp_list), c='red')\n",
    "\n",
    "ax.set_ylim(35.4,36.6)\n",
    "\n",
    "ax.set_xlabel('Day of Year')\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "ax.set_title('Modeled Gulf Stream S and T')\n",
    "\n",
    "annual_sal_mean = np.mean(sal_est)\n",
    "annual_temp_mean = np.mean(temp_est)\n",
    "\n",
    "# fig.savefig('sine_model_s_t.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines some parameters for the echosounder backscatter calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_gs_depth = 8*2\n",
    "shelf_depth = 8*2\n",
    "\n",
    "gulf_stream_ek = []\n",
    "eddy_ek = []\n",
    "shelf_ek = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['ekbackscatter'] = np.nan\n",
    "profiles['current_mag'] = np.nan\n",
    "\n",
    "for idx,fn in enumerate(filenames):\n",
    "    if idx in [0,1,2,3]:\n",
    "        continue\n",
    "    try:\n",
    "        ##########\n",
    "#     else:\n",
    "        dist = scipy.io.loadmat(fn+'_distance.mat')['distance']\n",
    "        sst = scipy.io.loadmat(fn+'_SST.mat')['SST']\n",
    "        time = scipy.io.loadmat(fn+'_time.mat')['time']\n",
    "        timestamps = pd.to_datetime(time[0,:]-719529, unit='D')\n",
    "       \n",
    "        \n",
    "#         if idx in [5,28,39,40,41]:\n",
    "#             dist = (dist - dist[-1])*-1\n",
    "        \n",
    "        X = scipy.io.loadmat(fn+'_X.mat')['X']\n",
    "        Y = scipy.io.loadmat(fn+'_Y.mat')['Y']\n",
    "        vMag = scipy.io.loadmat(fn+'_vmag.mat')['C']\n",
    "\n",
    "        vDir = scipy.io.loadmat(fn+'_vdir.mat')['C']\n",
    "        \n",
    "        vShear = scipy.io.loadmat(fn+'_vshear.mat')['C']\n",
    "        \n",
    "        echo = scipy.io.loadmat(fn+'_echo.mat')['C']\n",
    "        Xecho = scipy.io.loadmat(fn+'_Xecho.mat')['X']\n",
    "        Yecho = scipy.io.loadmat(fn+'_Yecho.mat')['Y']\n",
    "        \n",
    "        # correcting for the smaller bin size\n",
    "        Yecho = (Yecho*0.502)-1\n",
    "        \n",
    "        echo_reshape = echo.reshape(-1,127).T\n",
    "        vMag_reshape = vMag.reshape(-1,69).T\n",
    "        \n",
    "        lat = scipy.io.loadmat(fn+'_lat.mat')['lat']\n",
    "        long = scipy.io.loadmat(fn+'_long.mat')['long']\n",
    "        \n",
    "        # the distances are crazy wrong sometimes so re-calcuating the distance\n",
    "        coords_1 = (lat[0], long[0])\n",
    "        distances = []\n",
    "        for i in range(len(lat)):\n",
    "            coords_2 = (lat[i], long[i])\n",
    "            distances.append(distance.geodesic(coords_1, coords_2).meters)\n",
    "        dist = np.array(distances)       \n",
    "#         bogus_dist_locations = dist > 35000        \n",
    "#         dist[dist > 25000] = np.nan\n",
    "#         dist = pd.Series(dist).interpolate().values\n",
    "        # checking if the current point is within 500 of one that was good, assuming the first point is good\n",
    "        # then if not setting it to nan and interpolating it out\n",
    "        last_good_idx = 0\n",
    "        bad_idxs = []\n",
    "        for di,d in enumerate(dist):\n",
    "            if dist[di] - dist[last_good_idx] < 500:\n",
    "                last_good_idx = di\n",
    "            else:\n",
    "                bad_idxs.append(di)\n",
    "        dist[bad_idxs] = np.nan\n",
    "        dist = pd.Series(dist).interpolate().values\n",
    "\n",
    "        dist = dist.reshape(-1,1)\n",
    "        \n",
    "        adcp_df = pd.DataFrame({'dt':timestamps,\n",
    "                    'datetime':timestamps,\n",
    "                    'sst':sst[:,0],\n",
    "                    'lat': lat[:,0],\n",
    "                    'lon':long[:,0],\n",
    "                    'dist':dist[:,0]})\n",
    "\n",
    "        adcp_df = adcp_df.set_index('dt')\n",
    "        adcp_df = adcp_df.sort_index(ascending=True)\n",
    "        \n",
    "        \n",
    "        # find the adcp data with the closest location to each profile in distance space \n",
    "        # and then grab the echosounder data from that\n",
    "        \n",
    "        # the logic could be\n",
    "        # grab the closest ek sounding in time with the profile data\n",
    "        # then use that distance to average +/- the last 10 EK soundings\n",
    "        # interpolate that into the profile depth and don't extrapolate\n",
    "        # do this for each transect via just having a time tolerance of ~30 seconds\n",
    "        profiles_subset = profiles.loc[timestamps[0]:timestamps[-1]]\n",
    "        profiles_subset = profile_locs(profiles_subset, adcp_df)\n",
    "        \n",
    "        profile_nums = profiles_subset.profile_num.unique()\n",
    "        profile_num_idx = 0\n",
    "\n",
    "        for row in profiles_subset.itertuples(index=False):\n",
    "            try:\n",
    "                if row.profile_num == profile_nums[profile_num_idx]:\n",
    "#                     print(np.abs(dist - row.dist).min())\n",
    "                    dist_arg = np.abs(dist - row.dist).argmin()\n",
    "                    # we don't want the matchs to be very far away and better to keep as nans if so\n",
    "                    if np.abs(dist - row.dist).min() > 5:\n",
    "                        print('greater than 5m')\n",
    "                        continue\n",
    "                    ek_for_profile = np.interp(abs(profiles_subset[profiles_subset.profile_num == profile_nums[profile_num_idx]]['depth (dBars)'].values), abs(Yecho[:127,0]), np.nanmedian(echo_reshape[:,dist_arg-20:dist_arg+20],axis=1),left=np.nan, right=np.nan)\n",
    "                    mag_for_profile = np.interp(abs(profiles_subset[profiles_subset.profile_num == profile_nums[profile_num_idx]]['depth (dBars)'].values), abs(Y[:69,0]), np.nanmedian(vMag_reshape[:,dist_arg-20:dist_arg+20],axis=1),left=np.nan, right=np.nan)\n",
    "         \n",
    "                    \n",
    "                    m = profiles_subset.profile_num == profile_nums[profile_num_idx]\n",
    "                    \n",
    "                    profiles_subset.loc[m,'ekbackscatter'] = ek_for_profile\n",
    "                    profiles_subset.loc[m,'current_mag'] = mag_for_profile\n",
    "                    \n",
    "                    profile_num_idx+=1\n",
    "\n",
    "            except IndexError:\n",
    "        #         print('index error')\n",
    "                pass\n",
    "\n",
    "        profiles.loc[timestamps[0]:timestamps[-1],'ekbackscatter'] = profiles_subset.ekbackscatter \n",
    "        profiles.loc[timestamps[0]:timestamps[-1],'current_mag'] = profiles_subset.current_mag \n",
    "#         break\n",
    "        \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek_for_profile = np.interp(abs(profiles_subset[profiles_subset.profile_num == profile_nums[profile_num_idx-1]]['depth (dBars)'].values), abs(Yecho[:127,0]), np.nanmedian(echo_reshape[:,dist_arg-20:dist_arg+20],axis=1),left=np.nan, right=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ek_for_profile,profiles_subset[profiles_subset.profile_num == profile_nums[profile_num_idx-1]]['depth (dBars)'].values)\n",
    "plt.plot(np.nanmedian(echo_reshape[:,dist_arg-20:dist_arg+20],axis=1),Yecho[:127,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmag_for_profile = np.interp(abs(profiles_subset[profiles_subset.profile_num == profile_nums[profile_num_idx-1]]['depth (dBars)'].values), abs(Y[:69,0]), np.nanmedian(vMag_reshape[:,dist_arg-20:dist_arg+20],axis=1),left=np.nan, right=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmag_for_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vmag_for_profile,profiles_subset[profiles_subset.profile_num == profile_nums[profile_num_idx-1]]['depth (dBars)'].values)\n",
    "plt.plot(np.nanmedian(vMag_reshape[:,dist_arg-20:dist_arg+20],axis=1),Y[:69,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out boudaries (mins and maxs)\n",
    "smin = 32-.7\n",
    "smax = 37+.7\n",
    "tmin = 8-.7 \n",
    "tmax = 30+.7\n",
    "\n",
    "# Calculate how many gridcells we need in the x and y dimensions\n",
    "xdim = int(round((smax-smin)/0.1+1,0))\n",
    "ydim = int(round((tmax-tmin)+1,0))\n",
    " \n",
    "# Create empty grid of zeros\n",
    "dens = np.zeros((ydim,xdim))\n",
    " \n",
    "# Create temp and salt vectors of appropiate dimensions\n",
    "ti = np.linspace(1,ydim-1,ydim)+tmin\n",
    "si = np.linspace(1,xdim-1,xdim)*0.1+smin\n",
    " \n",
    "# Loop to fill in grid with densities\n",
    "for j in range(0,int(ydim)):\n",
    "    for i in range(0, int(xdim)):\n",
    "        dens[j,i]=gsw.rho(si[i],ti[j],0)\n",
    "\n",
    "# Substract 1000 to convert to sigma-t\n",
    "dens = dens - 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiles['cluster'] = kmeans.labels_\n",
    "\n",
    "profs_turb_sub['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_grouped.dist,df_tmp_grouped['potential density (kg/m^3 -1000)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_transects = []\n",
    "front_locations = []\n",
    "time_starts = []\n",
    "time_stops = []\n",
    "\n",
    "for idx,fn in enumerate(filenames):\n",
    "#     if idx not in tentative_good_idxs:\n",
    "# #         continue\n",
    "    if idx in [0,1,2,3]:\n",
    "        continue\n",
    "#     if idx not in [16, 17, 30, 36,43, 49,52,64]:\n",
    "#         continue\n",
    "#     if idx != 9:\n",
    "#         continue\n",
    "#     if idx not in [38,58]:\n",
    "#         continue\n",
    "\n",
    "    print(idx)\n",
    "    print(fn)\n",
    "    print('---')\n",
    "    print(datetimes[idx].strftime(\"%d. %B %Y %I:%M%p UTC\"))\n",
    "    \n",
    "    try:\n",
    "\n",
    "        dist = scipy.io.loadmat(fn+'_distance.mat')['distance']\n",
    "        sst = scipy.io.loadmat(fn+'_SST.mat')['SST']\n",
    "        time = scipy.io.loadmat(fn+'_time.mat')['time']\n",
    "        timestamps = pd.to_datetime(time[0,:]-719529, unit='D')\n",
    "    \n",
    "       \n",
    "        \n",
    "#         if idx in [5,28,39,40,41]:\n",
    "#             dist = (dist - dist[-1])*-1\n",
    "        \n",
    "        X = scipy.io.loadmat(fn+'_X.mat')['X']\n",
    "        Y = scipy.io.loadmat(fn+'_Y.mat')['Y']\n",
    "        vMag = scipy.io.loadmat(fn+'_vmag.mat')['C']\n",
    "\n",
    "        vDir = scipy.io.loadmat(fn+'_vdir.mat')['C']\n",
    "        \n",
    "        vShear = scipy.io.loadmat(fn+'_vshear.mat')['C']\n",
    "        \n",
    "        echo = scipy.io.loadmat(fn+'_echo.mat')['C']\n",
    "        Xecho = scipy.io.loadmat(fn+'_Xecho.mat')['X']\n",
    "        Yecho = scipy.io.loadmat(fn+'_Yecho.mat')['Y']\n",
    "        \n",
    "        # correcting for the smaller bin size\n",
    "        Yecho = (Yecho*0.502)-1\n",
    "        \n",
    "        lat = scipy.io.loadmat(fn+'_lat.mat')['lat']\n",
    "        long = scipy.io.loadmat(fn+'_long.mat')['long']\n",
    "        \n",
    "        # the distances are crazy wrong sometimes so re-calcuating the distance\n",
    "        coords_1 = (lat[0], long[0])\n",
    "        distances = []\n",
    "        for i in range(len(lat)):\n",
    "            coords_2 = (lat[i], long[i])\n",
    "            distances.append(distance.geodesic(coords_1, coords_2).meters)\n",
    "        dist = np.array(distances)       \n",
    "#         bogus_dist_locations = dist > 35000        \n",
    "#         dist[dist > 25000] = np.nan\n",
    "#         dist = pd.Series(dist).interpolate().values\n",
    "        # checking if the current point is within 500 of one that was good, assuming the first point is good\n",
    "        # then if not setting it to nan and interpolating it out\n",
    "        last_good_idx = 0\n",
    "        bad_idxs = []\n",
    "        for di,d in enumerate(dist):\n",
    "            if dist[di] - dist[last_good_idx] < 500:\n",
    "                last_good_idx = di\n",
    "            else:\n",
    "                bad_idxs.append(di)\n",
    "        dist[bad_idxs] = np.nan\n",
    "        dist = pd.Series(dist).interpolate().values\n",
    "\n",
    "        dist = dist.reshape(-1,1)\n",
    "        \n",
    "        adcp_df = pd.DataFrame({'dt':timestamps,\n",
    "                    'datetime':timestamps,\n",
    "                    'sst':sst[:,0],\n",
    "                    'lat': lat[:,0],\n",
    "                    'lon':long[:,0],\n",
    "                    'dist':dist[:,0]})\n",
    "\n",
    "        adcp_df = adcp_df.set_index('dt')\n",
    "        adcp_df = adcp_df.sort_index(ascending=True)\n",
    "        \n",
    "        adcp_gdf = gpd.GeoDataFrame(\n",
    "            adcp_df, geometry=gpd.points_from_xy(adcp_df.lon, adcp_df.lat))\n",
    "        \n",
    "        ##################\n",
    "        # calculate the front\n",
    "        \n",
    "        sal_vmp, temp_vmp, chla_vmp, turb_vmp, dt_vmp, dist_vmp  = grab_vmp_data(profiles, adcp_df, timestamps[0],timestamps[-1])\n",
    "        \n",
    "        # find the location using the salinity gs threshold I made and then find where the change happens\n",
    "        sal_est = provide_gs_sal_threshold(timestamps[0].timetuple().tm_yday, buffer=0.6)\n",
    "        gs_water = sal_vmp > sal_est\n",
    "        idx_of_sal_front = np.where(gs_water[:-1] != gs_water[1:])[0]\n",
    "        sal_front_location = (dist_vmp[idx_of_sal_front]+dist_vmp[idx_of_sal_front+1])/2\n",
    "#         if not sal_front_location.size > 0:\n",
    "#             continue\n",
    "            \n",
    "        front_transects.append(idx)\n",
    "        front_locations.append(sal_front_location)\n",
    "        time_starts.append(timestamps[0])\n",
    "        time_stops.append(timestamps[-1])\n",
    "#         if True:\n",
    "#             continue\n",
    "        \n",
    "        \n",
    "        ###################\n",
    "        # GOES STUFF\n",
    "        \n",
    "        # find the time step with the most data\n",
    "        da_subset = goes_ds.sel(time=slice((adcp_df.datetime.min()-timedelta(hours=24)), (adcp_df.datetime.max()+timedelta(hours=24)))).sea_surface_temperature\n",
    "        max_coverage_index = da_subset.count(dim=['latitude','longitude']).argmax()\n",
    "\n",
    "        ###################\n",
    "        \n",
    "        ########################################\n",
    "        \n",
    "        f = plt.figure(figsize=(30,5))\n",
    "        ax = f.add_subplot(141, projection=crs.PlateCarree())\n",
    "        ax2 = f.add_subplot(142, projection=crs.PlateCarree())\n",
    "        ax3 = f.add_subplot(143)\n",
    "        \n",
    "        \n",
    "        ax4 = f.add_subplot(144)\n",
    "        \n",
    "        ax.set_title('Location of Transect and SSH Front (0.25m)')\n",
    "        ax2.set_title('Location Zoom')\n",
    "        ax4.set_title('Annual SST Cycle')\n",
    "        \n",
    "#         da_subset[max_coverage_index].plot(ax=ax, cmap='inferno')\n",
    "        goes_ds.sel(time=slice((adcp_df.datetime.min()-timedelta(hours=18)), (adcp_df.datetime.max()+timedelta(hours=18)))).sea_surface_temperature.mean(dim='time').plot(ax=ax, cmap=cmocean.cm.thermal)\n",
    "\n",
    "        ax.coastlines(resolution='10m')\n",
    "        adcp_gdf.plot(ax=ax, markersize=2, color='green', alpha=1)\n",
    "#         front_gdf.iloc[front_gdf.index.get_loc(timestamps[0],method='nearest')-1:front_gdf.index.get_loc(timestamps[0],method='nearest')].plot(ax=ax, label='Todays SSH Front')\n",
    "#         front_gdf_median.plot(ax=ax, color='black',alpha=0.3, label='Average SSH Front')\n",
    "        \n",
    "#         ax.legend()\n",
    "                                                    \n",
    "#         ax.set_ylim(35.13000031,36.40999985)\n",
    "#         ax.set_xlim(-75.99000549,-74.11000061)\n",
    "        # ax.set_ylim(35.43000031,36.40999985)\n",
    "        # ax.set_xlim(-74.99000549,-74.11000061)\n",
    "        \n",
    "        \n",
    "        adcp_gdf.plot(ax=ax2, markersize=2, column='sst', alpha=1,  cmap='inferno', legend=True)\n",
    "#         da_subset[max_coverage_index].plot(ax=ax2, vmin=24.5, vmax=30, cmap='inferno')\n",
    "        \n",
    "        \n",
    "        ##################\n",
    "        \n",
    "#         ax3.scatter(sal_vmp,temp_vmp, c=dist_vmp)\n",
    "        ax3.scatter(dist_vmp,temp_vmp, color='red', label='Temp')\n",
    "        for sal_front in sal_front_location:\n",
    "            ax3.axvline(sal_front, c='k', ls='--')\n",
    "        ax3_twin = ax3.twinx()\n",
    "        ax3_twin.scatter(dist_vmp,sal_vmp, color='blue', label='Salinity')\n",
    "        ax3_twin.set_ylim(30,36.5)\n",
    "            \n",
    "        temp_est = provide_gs_temp_threshold(timestamps[0].timetuple().tm_yday)\n",
    "        ax3.axhline(temp_est, ls='--', c='red', label='T Gulf Stream')\n",
    "        ax3_twin.axhline(sal_est, ls='--', c='blue', label='S Gulf Stream')\n",
    "        \n",
    "        ax3_twin.legend(loc='lower left')\n",
    "        ax3.legend(loc='lower right')\n",
    "    \n",
    "        ax3.plot(dist,sst, color='red')\n",
    "        ax3.set_title(\"T and S (from 0 to 10 m)\")\n",
    "        ax3.set_ylabel('Temp (C)')\n",
    "        ax3.set_xlabel('Dist from Start (m)')\n",
    "        ax3.set_ylim(15,30)\n",
    "#         ax3.axvline(dist[front_location],color='grey', ls='--')\n",
    "\n",
    "        if idx not in [5,28,39,40,41]:\n",
    "            ax3.set_xlim(dist.max(),0)    \n",
    "        else:\n",
    "            ax3.set_xlim(0,dist.max())\n",
    "        \n",
    "\n",
    "#         ax2.scatter(long[front_location],lat[front_location],s=100,c='grey')\n",
    "\n",
    "        ####################\n",
    "        # this plots the annual chla data \n",
    "\n",
    "#         ax3.plot(dates_x_chla,chla_mean.gs_chla, c='blue', label='Gulf Stream')\n",
    "#         ax3.plot(dates_x_chla,chla_mean.gs_chla+chla_std.gs_chla, c='blue', alpha=0.2)\n",
    "#         ax3.plot(dates_x_chla,chla_mean.gs_chla-chla_std.gs_chla, c='blue', alpha=0.2)\n",
    "\n",
    "#         ax3.plot(dates_x_chla,chla_mean.coastal_chla, c='green', label='Coastal')\n",
    "#         ax3.plot(dates_x_chla,chla_mean.coastal_chla+chla_std.coastal_chla, c='green', alpha=0.2)\n",
    "#         ax3.plot(dates_x_chla,chla_mean.coastal_chla-chla_std.coastal_chla, c='green', alpha=0.2)\n",
    "\n",
    "#         ax3.set_ylim(0,2.75)\n",
    "        \n",
    "#         ax3.axvline(timestamps[0].timetuple().tm_yday, c='black')\n",
    "#         ax3.set_xlim(0,365)\n",
    "        \n",
    "#         ax3.legend()\n",
    "\n",
    "#         ax3.set_ylabel('Chla (mg/m3)')\n",
    "#         ax3.set_xlabel('Day of Year')\n",
    "        \n",
    "        #################\n",
    "        \n",
    "#         ax4.scatter([dt_element.timetuple().tm_yday for dt_element in datetimes_subset],np.nanmax(interp_sst_list,axis=1)+273, color='blue')\n",
    "#         ax4.scatter([dt_element.timetuple().tm_yday for dt_element in datetimes_subset],np.nanmin(interp_sst_list,axis=1)+273, color='green')\n",
    "        \n",
    "\n",
    "        ax4.plot(dates_x_sst,sst_mean.gs_sst, c='blue', label='Gulf Stream')\n",
    "        ax4.plot(dates_x_sst,sst_mean.gs_sst+sst_std.gs_sst, c='blue', alpha=0.2)\n",
    "        ax4.plot(dates_x_sst,sst_mean.gs_sst-sst_std.gs_sst, c='blue', alpha=0.2)\n",
    "\n",
    "        ###################\n",
    "\n",
    "        ax4.plot(dates_x_sst,sst_mean.coastal_sst, c='green', label='Coastal')\n",
    "        ax4.plot(dates_x_sst,sst_mean.coastal_sst+sst_std.coastal_sst, c='green', alpha=0.2)\n",
    "        ax4.plot(dates_x_sst,sst_mean.coastal_sst-sst_std.coastal_sst, c='green', alpha=0.2)\n",
    "\n",
    "        ################3\n",
    "\n",
    "        ax4.legend(loc='lower right')\n",
    "\n",
    "        ax4.set_ylabel('SST (K)')\n",
    "        ax4.set_xlabel('Day of Year')\n",
    "        \n",
    "        ax4.axvline(timestamps[0].timetuple().tm_yday, c='black', label='Current Day')\n",
    "        ax4.set_xlim(0,365)\n",
    "        ax4.legend()\n",
    "        \n",
    "        \n",
    "        ########################################\n",
    "        \n",
    "        ax = plot_profiles(profiles, adcp_df, timestamps[0],timestamps[-1], ['potential density (kg/m^3 -1000)','temp (C)', 'salinity (PSU)', 'chla (ppb)'], plot=True)\n",
    "        if idx not in [5,28,39,40,41]:\n",
    "            for i in range(4):\n",
    "                ax[i].set_xlim(dist.max(),0)    \n",
    "        else:\n",
    "            for i in range(4):\n",
    "                ax[i].set_xlim(0,dist.max())\n",
    "        for i in range(4):\n",
    "            ax[i].set_ylim(-100,-1)\n",
    "#             for sal_front in sal_front_location:\n",
    "#                 ax[i].axvline(sal_front, c='k', ls='--')\n",
    "#         plt.savefig('profiles'+str(idx)+'.png',dpi=300)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "        ########################################\n",
    "        \n",
    "        \n",
    "        fig, ax = plt.subplots(1,1, figsize=(8,5))\n",
    "        \n",
    "       \n",
    "        profiles_subset = profiles.loc[timestamps[0]:timestamps[-1]]\n",
    "    \n",
    "        profiles_subset = profile_locs(profiles_subset, adcp_df)\n",
    "        \n",
    "#         integrate down to z depth\n",
    "        depths = [-5,-10,-20,-40,-60]\n",
    "        \n",
    "        colors = list(Color(\"black\").range_to(Color(\"blue\"),len(depths)))\n",
    "        hex_colors = [j.hex for j in colors]\n",
    "        \n",
    "        for idx_profs, z in enumerate(depths):\n",
    "            # cut it off at depth (dBars) >= z\n",
    "            df_tmp = profiles_subset[profiles_subset['depth (dBars)'] >= z] \n",
    "            df_tmp_grouped = df_tmp.groupby('profile_num').median()\n",
    "            df_tmp_grouped['datetime'] = pd.to_datetime('2021-1-1') + pd.to_timedelta(df_tmp_grouped.time, unit='D') - pd.Timedelta(days=1)\n",
    "            df_tmp_grouped = df_tmp_grouped.sort_values('dist')\n",
    "\n",
    "\n",
    "            ax.plot(df_tmp_grouped.dist,df_tmp_grouped['chla (ppb)'], label='chla mean(0'+str(z)+')', color=hex_colors[idx_profs], ls='--')\n",
    "            ax.scatter(df_tmp_grouped.dist,df_tmp_grouped['chla (ppb)'], color=hex_colors[idx_profs], ls='--')\n",
    "        \n",
    "        ax.set_ylim(-0.3,0.6)\n",
    "        \n",
    "        if idx not in [5,28,39,40,41]:\n",
    "            ax.set_xlim(dist.max(),0)\n",
    "        else:\n",
    "            ax.set_xlim(0,dist.max())\n",
    "\n",
    "\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "       \n",
    "\n",
    "        ########################################\n",
    "\n",
    "        fig, ax = plt.subplots(1,4, figsize=(30,5))\n",
    "\n",
    "\n",
    "        vMag_reshape = vMag.reshape(-1,69).T\n",
    "        vDir_reshape = vDir.reshape(-1,69).T\n",
    "        vShear_reshape = vShear.reshape(-1,68).T\n",
    "\n",
    "\n",
    "        x, y = np.meshgrid(dist,Y[:69,0])    \n",
    "        im = ax[0].pcolormesh(x,y,vMag_reshape,shading='gouraud', vmin=0,vmax=200)\n",
    "        fig.colorbar(im,ax=ax[0])\n",
    "        ax[0].set_title(\"Current Magnitude (cm/s)\")\n",
    "        ax[0].set_ylabel('Depth (m)')\n",
    "        ax[0].set_xlabel('Dist from Start (m)')\n",
    "\n",
    "        im = ax[1].pcolormesh(x,y,vDir_reshape,shading='gouraud', vmin=0,vmax=360, cmap='hsv')\n",
    "        fig.colorbar(im,ax=ax[1])\n",
    "        ax[1].set_title(\"Current Direction (Deg from North)\")\n",
    "        ax[1].set_ylabel('Depth (m)')\n",
    "        ax[1].set_xlabel('Dist from Start (m)')\n",
    "                \n",
    "        vgradient = []\n",
    "        \n",
    "        N=180\n",
    "        current_speed = np.mean(vMag_reshape[0:4,:],axis=0)\n",
    "        current_speed_smooth = pd.Series(current_speed).rolling(window=N).mean().iloc[N-1:].values\n",
    "        vgradient = []\n",
    "\n",
    "        step = 1\n",
    "\n",
    "        for i in range(len(current_speed)-N):\n",
    "            du = current_speed_smooth[i] - current_speed_smooth[i+step]\n",
    "            dx = dist[i] - dist[i+step]\n",
    "            current_grad = du/dx\n",
    "            vgradient.append(current_grad)\n",
    "            \n",
    "        dudx = scipy.signal.savgol_filter(current_speed_smooth, window_length=11, polyorder=2, deriv=1)\n",
    "\n",
    "#         ax_twin = ax[0].twinx()\n",
    "#         ax_twin.plot(dist[:-N+1], dudx, c='grey')\n",
    "#         ax_twin.set_ylim(-0.6,0.6)\n",
    "        \n",
    "#         ax_twin2 = ax[0].twinx()\n",
    "#         ax_twin2.plot(dist[:-N],current_speed_smooth[:-1],c='black')\n",
    "#         ax_twin2.set_ylim(0,200)\n",
    "        \n",
    "        Ndir=90\n",
    "        current_dir = np.mean(vDir_reshape[0:4,:],axis=0)\n",
    "        current_dir_smooth = pd.Series(current_dir).rolling(window=Ndir).mean().iloc[Ndir-1:].values\n",
    "        \n",
    "#         ax_dir = ax[1].twinx()\n",
    "#         ax_dir.plot(dist[:-Ndir+1],current_dir_smooth)\n",
    "#         ax_dir.set_ylim(0,360)\n",
    "\n",
    "        # taking off the first 100 points because those are often noisy and never the front\n",
    "        front_location = np.argmax(np.abs(dudx[100:-30]))+100\n",
    "\n",
    "        echo_reshape = echo.reshape(-1,127).T\n",
    "        \n",
    "        x_trim = dist.shape[0] - echo_reshape.shape[1]\n",
    "\n",
    "        x, y = np.meshgrid(dist[:,0],Yecho[:127,0])      \n",
    "        \n",
    "        # this is actually maybe stupid so need to pull in the shear X and Y data\n",
    "        if x_trim >=0:\n",
    "            im = ax[3].pcolormesh(x[:,x_trim:],y[:,x_trim:],echo_reshape,shading='gouraud', vmin=96,vmax=115, cmap='jet')\n",
    "        else:\n",
    "            im = ax[3].pcolormesh(x,y,echo_reshape[:,:x_trim],shading='gouraud', vmin=96,vmax=115, cmap='jet')\n",
    "        \n",
    "        \n",
    "#         im = ax[3].pcolormesh(x,y,echo_reshape,shading='gouraud', vmin=96,vmax=115, cmap='jet')\n",
    "        fig.colorbar(im,ax=ax[3])\n",
    "#         ax[3].axvline(dist[front_location],color='grey', ls='--')\n",
    "        ax[3].set_title(\"Echo Volume Backscatter (sV)\")\n",
    "        ax[3].set_ylabel('Depth (m)')\n",
    "        ax[3].set_xlabel('Dist from Start (m)')\n",
    "        ax[3].set_ylim(-100,-1)\n",
    "        \n",
    "        if idx not in [5,28,39,40,41]:\n",
    "            for i in range(4):\n",
    "                ax[i].set_xlim(dist.max(),0)    \n",
    "        else:\n",
    "            for i in range(4):\n",
    "                ax[i].set_xlim(0,dist.max())\n",
    "        for i in range(4):\n",
    "            ax[i].set_ylim(-100,-1)\n",
    "#             ax[i].axvline(dist[front_location],color='grey', ls='--', label='current front')\n",
    "            \n",
    "#             ax[i].scatter(dist[bad_idxs],[-68]*len(dist[bad_idxs]),color='red')\n",
    "# #             for sal_front in sal_front_location:\n",
    "#                 ax[i].axvline(sal_front, c='k', ls='--', label='sal front')\n",
    "#         ax[0].legend(loc='lower right')\n",
    "\n",
    "    #     fig.savefig('sst_mag_dir_'+str(transect_num[idx])+'.png',dpi=400)\n",
    "#         fig.tight_layout()\n",
    "\n",
    "        x_trim = dist.shape[0] - vShear_reshape.shape[1]\n",
    "\n",
    "        x, y = np.meshgrid(dist[:,0],Y[:68,0])  \n",
    "        \n",
    "        # this is actually maybe stupid so need to pull in the shear X and Y data\n",
    "        if x_trim >=0:\n",
    "            im = ax[2].pcolormesh(x[:,x_trim:],y,vShear_reshape,shading='gouraud', vmin=0.01,vmax=.09, cmap='cividis')\n",
    "        else:\n",
    "            im = ax[2].pcolormesh(x,y,vShear_reshape[:,:x_trim],shading='gouraud', vmin=0.01,vmax=.09, cmap='cividis')\n",
    "        fig.colorbar(im,ax=ax[2])\n",
    "        ax[2].set_title(\"Current Shear\")\n",
    "        ax[2].set_ylabel('Depth (m)')\n",
    "        ax[2].set_xlabel('Dist from Start (m)')\n",
    "        \n",
    "        plt.savefig('adcp'+str(idx)+'.png',dpi=300)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        ###########\n",
    "        \n",
    "        profiles_subset = profiles.loc[timestamps[0]:timestamps[-1]]\n",
    "    \n",
    "        profiles_subset = profile_locs(profiles_subset, adcp_df)\n",
    "        \n",
    "                \n",
    "        # plot T and S diagrams first with distance from coast and then with other variables\n",
    "        fig, ax = plt.subplots(1,4, figsize=(30,5))\n",
    "        markersize=40\n",
    "\n",
    "        for i in range(4):\n",
    "            ax[i].set_xlim(32,37)\n",
    "            ax[i].set_ylim(8,30)\n",
    "            ax[i].set_xlabel('Salinity')\n",
    "            ax[i].set_ylabel('Temperature (C)')\n",
    "\n",
    "            CS = ax[i].contour(si,ti,dens, linestyles='dashed', colors='k', alpha=0.5)\n",
    "            ax[i].clabel(CS, fontsize=12, inline=1, fmt='%1.1f') # Label every second level\n",
    "            # ellipse = Ellipse(xy=(35.88, 28.05), width=0.5, height=1.2, angle=-20,\n",
    "            #                 edgecolor='k', fc='None', ls='--', lw=2)\n",
    "            # ax.add_patch(ellipse)\n",
    "\n",
    "        # im = ax.scatter(np.concatenate(vmp_sal_list), np.concatenate(vmp_temp_list), c=np.concatenate(vmp_chla_list), vmin=-0.5,vmax=0.5,alpha=0.4)#c=np.concatenate(vmp_dt_list), vmin=0,vmax=365, cmap='twilight')\n",
    "        im = ax[0].scatter(profiles_subset['salinity (PSU)'], profiles_subset['temp (C)'], c=profiles_subset['depth (dBars)'], cmap=cmocean.cm.deep_r, alpha=1, vmin=-70,vmax=0)\n",
    "        fig.colorbar(im,ax=ax[0])\n",
    "        ax[0].set_title('Profile Depth')\n",
    "        im = ax[1].scatter(profiles_subset['salinity (PSU)'], profiles_subset['temp (C)'], c=profiles_subset['chla (ppb)'], cmap=cmocean.cm.algae,\n",
    "                          vmax=np.percentile(profiles_subset['chla (ppb)'], 95),vmin=np.percentile(profiles_subset['chla (ppb)'], 5), alpha=1)\n",
    "        fig.colorbar(im,ax=ax[1])\n",
    "        ax[1].set_title('Profile Chla')\n",
    "        im = ax[2].scatter(profiles_subset['salinity (PSU)'], profiles_subset['temp (C)'], c=profiles_subset['turbidity (FTU)'], cmap=cmocean.cm.turbid, \n",
    "                           vmax=np.percentile(profiles_subset['turbidity (FTU)'], 95),vmin=np.percentile(profiles_subset['turbidity (FTU)'], 5), alpha=1)\n",
    "        fig.colorbar(im,ax=ax[2])\n",
    "        ax[2].set_title('Profile Turbidity')\n",
    "        \n",
    "#         im = ax[3].scatter(profiles['salinity (PSU)'], profiles['temp (C)'], c=profiles.datetime.dt.day_of_year, cmap=cmocean.cm.phase,vmin=0,vmax=365,alpha=0.8)\n",
    "#         im = ax[3].scatter(profs_turb_sub['salinity (PSU)'], profs_turb_sub['temp (C)'], c=profs_turb_sub['cluster'], cmap='jet',vmin=0,vmax=6,alpha=0.05)\n",
    "#         fig.colorbar(im,ax=ax[3])\n",
    "# #         ax[3].set_title('All Transects/Profiles DOY')\n",
    "#         ax[3].set_title('All Profiles Clusters')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        ######\n",
    "        #### calc decorrelation scales\n",
    "\n",
    "#         fig, ax = plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "#         depth_max = [0,-15,-25,-35]\n",
    "#         depth_min = [-10,-25,-35,-45]\n",
    "#         vars_for_calc = ['salinity (PSU)','current_mag','ekbackscatter']\n",
    "\n",
    "#         for var_i, ax in enumerate([ax[0],ax[1],ax[2]]):\n",
    "\n",
    "#             var_for_cal = vars_for_calc[var_i]\n",
    "\n",
    "#             ax2=ax.twinx()\n",
    "#             ax.axhline(0,ls='--', c='k')\n",
    "#             for depth_i in range(len(depth_max)):\n",
    "#                 input_df = profiles_subset[(profiles_subset['depth (dBars)'] < depth_max[depth_i]) & (profiles_subset['depth (dBars)'] > depth_min[depth_i])].groupby('profile_num',dropna=False).mean()\n",
    "#                 input_df = input_df.reindex(index=natsorted(input_df.index))\n",
    "#                 nlags = len(input_df)-1\n",
    "\n",
    "#                 ax2.plot(input_df['dist'],input_df[var_for_cal],label=var_for_cal+' '+str(depth_max[depth_i]) + ' to ' +str(depth_min[depth_i]),ls='--')\n",
    "#                 ax.plot(input_df['dist'],sm.tsa.acf(input_df[var_for_cal],nlags=nlags), label='autocorr '+var_for_cal+' '+str(depth_max[depth_i]) + ' to ' +str(depth_min[depth_i]))\n",
    "#                 ax.set_title(var_for_cal)\n",
    "#                 ax.legend(loc='lower left',bbox_to_anchor=(-0.1, -0.25))\n",
    "#                 ax2.legend(loc='lower right',bbox_to_anchor=(1.05, -0.25))\n",
    "#         plt.show()\n",
    "        \n",
    "#         fig, ax = plt.subplots()\n",
    "#         p_sub = profiles_subset[profiles_subset['depth (dBars)'] > -45]\n",
    "#         correls = []\n",
    "#         for p in p_sub.profile_num.unique():\n",
    "#             correls.append([crosscorr(p_sub[p_sub.profile_num == p].chla_clean, p_sub[p_sub.profile_num == p].ekbackscatter, lag=i) for i in range(50)])\n",
    "#         correls = np.array(correls)\n",
    "#         ax.scatter([list(range(50))]*correls.shape[0],correls,alpha=0.4)\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "        #########################\n",
    "#         calculate the watermass backscatter values\n",
    "#         if idx == 39:\n",
    "#             gulf_stream_ek.append(echo_reshape[:ed_gs_depth,:].flatten())\n",
    "#         elif idx == 40:\n",
    "#             shelf_dist_arg = (np.abs(dist - 4000)).argmin()\n",
    "#             shelf_ek.append(echo_reshape[:shelf_depth,:shelf_dist_arg].flatten())                   \n",
    "#             eddy_ek.append(echo_reshape[:ed_gs_depth,shelf_dist_arg:].flatten())\n",
    "#         elif idx == 41:\n",
    "#             shelf_dist_arg = (np.abs(dist - 4000)).argmin()\n",
    "#             shelf_ek.append(echo_reshape[:shelf_depth,:shelf_dist_arg].flatten())\n",
    "#             gs_start_dist_arg = (np.abs(dist - 9000)).argmin()\n",
    "#             gs_end_dist_arg = (np.abs(dist - 13000)).argmin()\n",
    "#             gulf_stream_ek.append(echo_reshape[:ed_gs_depth,gs_start_dist_arg:gs_end_dist_arg].flatten())\n",
    "#         elif idx == 42:\n",
    "#             ed_start_dist_arg = (np.abs(dist - 3000)).argmin()\n",
    "#             ed_end_dist_arg = (np.abs(dist - 21000)).argmin()\n",
    "#             eddy_ek.append(echo_reshape[:ed_gs_depth,ed_start_dist_arg:ed_end_dist_arg].flatten())\n",
    "\n",
    "        ########################################\n",
    "        \n",
    "#         fig, ax = plt.subplots(1,3, figsize=(30,5))\n",
    "#         im = ax[0].scatter(long,lat,c=sst[:,0], cmap='inferno')\n",
    "#         fig.colorbar(im,ax=ax[0])\n",
    "#         ax[0].scatter(long[front_location],lat[front_location],s=100,c='grey')\n",
    "#         ax[0].set_title(\"Location (and SST)\")\n",
    "\n",
    "#         echo_reshape = echo.reshape(-1,127).T\n",
    "        \n",
    "#         Ndir=90\n",
    "#         current_dir = np.mean(vDir_reshape[0:4,:],axis=0)\n",
    "#         current_dir_smooth = pd.Series(current_dir).rolling(window=Ndir).mean().iloc[Ndir-1:].values\n",
    "\n",
    "#         x, y = np.meshgrid(Xecho.reshape(-1,127)[:,0],Yecho[:127,0])    \n",
    "#         im = ax[1].pcolormesh(x,y,echo_reshape,shading='gouraud', vmin=96,vmax=115, cmap='jet')\n",
    "#         fig.colorbar(im,ax=ax[1])\n",
    "#         ax[1].axvline(dist[front_location],color='grey', ls='--')\n",
    "#         ax[1].set_title(\"Echo Volume Backscatter (sV)\")\n",
    "#         ax[1].set_ylabel('Depth (m)')\n",
    "#         ax[1].set_xlabel('Dist from Start (m)')\n",
    "#         ax[1].set_ylim(-70,-1)\n",
    "        \n",
    "       \n",
    "#         ax[2].plot(dist,sst, color='red')\n",
    "# #         ax[0].set_ylim(15,30)\n",
    "#         ax[2].set_title(\"SST (C) and Dir (from 10 m)\")\n",
    "#         ax[2].set_ylabel('Temp (C)')\n",
    "#         ax[2].set_xlabel('Dist from Start (m)')\n",
    "#         ax[2].set_ylim(15,30)\n",
    "#         ax[2].axvline(dist[front_location],color='grey', ls='--')\n",
    "        \n",
    "#         ax_dir = ax[2].twinx()\n",
    "#         ax_dir.plot(dist[:-Ndir+1],current_dir_smooth)\n",
    "#         ax_dir.set_ylim(0,360)\n",
    "        \n",
    "#         if idx in [5,28,39,40,41]:\n",
    "#             for i in range(1,3):\n",
    "#                 ax[i].set_xlim(dist.max(),0)\n",
    "# #         fig.tight_layout()\n",
    "#         plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    except Exception as e: \n",
    "        print('had an error')\n",
    "        print(e)\n",
    "        \n",
    "    print('##################################################################################################################################################')\n",
    "    print('##################################################################################################################################################')\n",
    "    print('##################################################################################################################################################')\n",
    "    print('##################################################################################################################################################')\n",
    "#         print('##################################################################################################################################################')\n",
    "#         print('##################################################################################################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The transects that seem to actually be in the GS and cross a current front are:\n",
    "    \n",
    "gs_current_idxs = [68, 67, 66, 65, 64, 63, 59, 58, 56, 52, 51, 50, 49, 48, 46, 45, 44, 43, 38, 36, 35, 34, 30, 29, 25, 22, 20, 17, 16, 13, 12, 10, 9, 8, 7, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# steps\n",
    "\n",
    "1. grab the data from these transects\n",
    "2. detect the main current front\n",
    "3. line them up in space with the current front as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(np.abs(dudx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(5.5,5))\n",
    "\n",
    "profiles_subset = profiles.loc[timestamps[0]:timestamps[-1]]\n",
    "\n",
    "profiles_subset = profile_locs(profiles_subset, adcp_df)\n",
    "\n",
    "#         integrate down to z depth\n",
    "depths = [-5,-10,-20,-40,-60]\n",
    "\n",
    "colors = list(Color(\"black\").range_to(Color(\"green\"),len(depths)))\n",
    "hex_colors = [j.hex for j in colors]\n",
    "\n",
    "colors = list(Color(\"red\").range_to(Color(\"yellow\"),len(depths)))\n",
    "hex_colors_red = [j.hex for j in colors]\n",
    "\n",
    "#     dist_centered = dist - single_front_locations[counter]\n",
    "\n",
    "ax_mag = ax.twinx()\n",
    "\n",
    "for idx_profs, z in enumerate(depths):\n",
    "    # cut it off at depth (dBars) >= z\n",
    "    df_tmp = profiles_subset[profiles_subset['depth (dBars)'] >= z] \n",
    "    df_tmp_grouped = df_tmp.groupby('profile_num').median()\n",
    "    df_tmp_grouped['datetime'] = pd.to_datetime('2021-1-1') + pd.to_timedelta(df_tmp_grouped.time, unit='D') - pd.Timedelta(days=1)\n",
    "    df_tmp_grouped = df_tmp_grouped.sort_values('dist')\n",
    "\n",
    "\n",
    "    ax.plot(df_tmp_grouped.dist,df_tmp_grouped['chla (ppb)'], label='chla mean(0'+str(z)+')', color=hex_colors[idx_profs], ls='-')\n",
    "    ax.scatter(df_tmp_grouped.dist,df_tmp_grouped['chla (ppb)'], color=hex_colors[idx_profs], ls='--')\n",
    "    \n",
    "    ax_mag.plot(df_tmp_grouped.dist,df_tmp_grouped['current_mag'], label='mag mean(0'+str(z)+')', color=hex_colors_red[idx_profs], ls='--')\n",
    "    ax_mag.scatter(df_tmp_grouped.dist,df_tmp_grouped['current_mag'], color=hex_colors_red[idx_profs], ls='--')\n",
    "    \n",
    "    if idx_profs == 0:\n",
    "\n",
    "        dudx = scipy.signal.savgol_filter(df_tmp_grouped['current_mag'], window_length=3, polyorder=2, deriv=1)\n",
    "        front_location = np.argmax(np.abs(dudx))\n",
    "        ax.axvline((df_tmp_grouped.dist[front_location]+df_tmp_grouped.dist[front_location+1])/2,color='k', ls='--')\n",
    "            \n",
    "    ax.set_ylim(-0.3,0.8)\n",
    "    ax.set_ylabel('chla')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles[profiles['chla (ppb)']>5]['chla (ppb)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(profiles[profiles['chla (ppb)']<2]['chla (ppb)'],bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['chla (ppb)'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['chla_adjusted'] = profiles['chla (ppb)']+.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['chla_adjusted'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(profiles[profiles['chla_adjusted']<2]['chla_adjusted'],bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles[profiles['chla (ppb)']<2]['chla (ppb)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_speed_smooth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig, ax = plt.subplots(5,2, figsize=(16, 14))\n",
    "i = 0\n",
    " \n",
    "# define window sizes 5, 11, 21, 31\n",
    "for poly in [1,2,3,4,5]:    \n",
    "    y_fit = scipy.signal.savgol_filter(current_speed_smooth, 501, poly, mode=\"nearest\")\n",
    "    ax[i,0].plot(dist[:-N+1],current_speed_smooth, label=\"y_signal\", color=\"green\")\n",
    "    ax[i,1].plot(dist[:-N+1], y_fit, label=\"y_smoothed\", color=\"red\")\n",
    "    for j in range(2):\n",
    "        ax[i,j].set_title(\"poly order: \" + str(poly))\n",
    "        ax[i,j].legend()\n",
    "        ax[i,j].grid(True)\n",
    "    i+=1\n",
    "\n",
    "plt.tight_layout()        \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,fn in enumerate(filenames):\n",
    "    if idx not in gs_current_idxs:\n",
    "        continue\n",
    "#     if idx != 64:\n",
    "#         continue\n",
    "    print(idx)\n",
    "    print(fn)\n",
    "    \n",
    "#     try:\n",
    "\n",
    "    dist = scipy.io.loadmat(fn+'_distance.mat')['distance']\n",
    "    sst = scipy.io.loadmat(fn+'_SST.mat')['SST']\n",
    "    time = scipy.io.loadmat(fn+'_time.mat')['time']\n",
    "    timestamps = pd.to_datetime(time[0,:]-719529, unit='D')\n",
    "\n",
    "    X = scipy.io.loadmat(fn+'_X.mat')['X']\n",
    "    Y = scipy.io.loadmat(fn+'_Y.mat')['Y']\n",
    "    vMag = scipy.io.loadmat(fn+'_vmag.mat')['C']\n",
    "\n",
    "    vDir = scipy.io.loadmat(fn+'_vdir.mat')['C']\n",
    "\n",
    "    echo = scipy.io.loadmat(fn+'_echo.mat')['C']\n",
    "    Xecho = scipy.io.loadmat(fn+'_Xecho.mat')['X']\n",
    "    Yecho = scipy.io.loadmat(fn+'_Yecho.mat')['Y']\n",
    "    # correcting for the smaller bin size\n",
    "    Yecho = (Yecho*0.502)-1\n",
    "\n",
    "    lat = scipy.io.loadmat(fn+'_lat.mat')['lat']\n",
    "    long = scipy.io.loadmat(fn+'_long.mat')['long']\n",
    "\n",
    "    # the distances are crazy wrong sometimes so re-calcuating the distance\n",
    "    coords_1 = (lat[0], long[0])\n",
    "    distances = []\n",
    "    for i in range(len(lat)):\n",
    "        coords_2 = (lat[i], long[i])\n",
    "        distances.append(distance.geodesic(coords_1, coords_2).meters)\n",
    "    dist = np.array(distances)       \n",
    "#         bogus_dist_locations = dist > 35000        \n",
    "#         dist[dist > 25000] = np.nan\n",
    "#         dist = pd.Series(dist).interpolate().values\n",
    "    # checking if the current point is within 500 of one that was good, assuming the first point is good\n",
    "    # then if not setting it to nan and interpolating it out\n",
    "    last_good_idx = 0\n",
    "    bad_idxs = []\n",
    "    for di,d in enumerate(dist):\n",
    "        if dist[di] - dist[last_good_idx] < 500:\n",
    "            last_good_idx = di\n",
    "        else:\n",
    "            bad_idxs.append(di)\n",
    "    dist[bad_idxs] = np.nan\n",
    "    dist = pd.Series(dist).interpolate().values\n",
    "\n",
    "    dist = dist.reshape(-1,1)\n",
    "    \n",
    "    adcp_df = pd.DataFrame({'dt':timestamps,\n",
    "                    'datetime':timestamps,\n",
    "                   'lat': lat[:,0],\n",
    "                   'lon':long[:,0],\n",
    "                           'dist':dist[:,0]})\n",
    "\n",
    "    adcp_df = adcp_df.set_index('dt')\n",
    "    adcp_df = adcp_df.sort_index(ascending=True)\n",
    "\n",
    "    ax = plot_profiles(profiles, adcp_df, timestamps[0],timestamps[-1], ['potential density (kg/m^3 -1000)','temp (C)', 'salinity (PSU)', 'chla (ppb)'], plot=True)\n",
    "    if idx not in [5,28,39,40,41]:\n",
    "        for i in range(4):\n",
    "            ax[i].set_xlim(dist.max(),0)    \n",
    "    else:\n",
    "        for i in range(4):\n",
    "            ax[i].set_xlim(0,dist.max())\n",
    "    for i in range(4):\n",
    "        ax[i].set_ylim(-80,-1)\n",
    "#             for sal_front in sal_front_location:\n",
    "#                 ax[i].axvline(sal_front, c='k', ls='--')\n",
    "#         plt.savefig('profiles'+str(idx)+'.png',dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(9.5,4))\n",
    "    vMag_reshape = vMag.reshape(-1,69).T\n",
    "    vDir_reshape = vDir.reshape(-1,69).T\n",
    "    \n",
    "    x, y = np.meshgrid(dist,Y[:69,0])  \n",
    "    im = ax.pcolormesh(x,y,vMag_reshape,shading='gouraud', vmin=0,vmax=250)\n",
    "    fig.colorbar(im,ax=ax)\n",
    "    ax.set_title(\"Current Magnitude (cm/s)\")\n",
    "\n",
    "    vgradient = []\n",
    "\n",
    "    N=180\n",
    "    current_speed = np.mean(vMag_reshape[0:4,:],axis=0)\n",
    "    current_speed_smooth = pd.Series(current_speed).rolling(window=N).mean().iloc[N-1:].values\n",
    "    vgradient = []\n",
    "\n",
    "    step = 1\n",
    "\n",
    "    for i in range(len(current_speed)-N):\n",
    "        du = current_speed_smooth[i] - current_speed_smooth[i+step]\n",
    "        dx = dist[i] - dist[i+step]\n",
    "        current_grad = du/dx\n",
    "        vgradient.append(current_grad)\n",
    "\n",
    "    dudx = scipy.signal.savgol_filter(current_speed_smooth, window_length=501, polyorder=2, deriv=1)\n",
    "\n",
    "    ax_twin = ax.twinx()\n",
    "#         ax_twin.plot(dist[15:-15-N], vgradient_smooth[15:-16], c='k', alpha=0.5)\n",
    "    ax_twin.plot(dist[:-N+1], dudx, c='grey', ls='--')\n",
    "    ax_twin.set_ylim(-0.6,0.6)\n",
    "\n",
    "    ax_twin2 = ax.twinx()\n",
    "    ax_twin2.plot(dist[:-N],current_speed_smooth[:-1],c='black')\n",
    "    ax_twin2.set_ylim(0,250)\n",
    "\n",
    "    ax_twin3 = ax.twinx()\n",
    "    ax_twin3.plot(dist,sst, color='red')\n",
    "    ax_twin3.set_ylim(18,30)\n",
    "    # taking off the first 100 points because those are often noisy and never the front\n",
    "    front_location = np.argmax(np.abs(dudx[100:-30]))+100\n",
    "\n",
    "    ax_twin.yaxis.label.set_color('grey')\n",
    "    ax_twin.spines['right'].set_position(('outward', 90))\n",
    "\n",
    "    ax_twin2.yaxis.label.set_color('black')\n",
    "    ax_twin2.spines['right'].set_position(('outward', 180))\n",
    "\n",
    "    ax_twin3.yaxis.label.set_color('red')\n",
    "    ax_twin3.spines['right'].set_position(('outward', 260))\n",
    "\n",
    "    ax_twin.set_ylabel('current gradient')\n",
    "    ax_twin2.set_ylabel('top 10m current speed (cm/s)')\n",
    "    ax_twin3.set_ylabel('SST (C)')\n",
    "\n",
    "\n",
    "    if idx not in [5,28,39,40,41]:\n",
    "        ax.set_xlim(dist.max(),0)\n",
    "    else:\n",
    "        ax.set_xlim(0,dist.max())\n",
    "    ax.axvline(dist[front_location],color='k', ls='--')\n",
    "    ax.set_ylim(-80,-2)\n",
    "    ax.set_ylabel('Depth (m)')\n",
    "    ax.set_xlabel('Dist from Start (m)')\n",
    "    ax.axvline(dist[front_location],color='k', ls='--')\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "#         fig.savefig('mag_dir_echo'+str(idx)+'.png',dpi=400)\n",
    "    plt.show()\n",
    "    \n",
    "    ##################################\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1, figsize=(5.5,5))\n",
    "    \n",
    "    ax.axvline(dist[front_location],color='k', ls='--')\n",
    "\n",
    "\n",
    "    profiles_subset = profiles.loc[timestamps[0]:timestamps[-1]]\n",
    "\n",
    "    profiles_subset = profile_locs(profiles_subset, adcp_df)\n",
    "\n",
    "    #         integrate down to z depth\n",
    "    depths = [-10,-20,-40,-60]\n",
    "\n",
    "    colors = list(Color(\"black\").range_to(Color(\"green\"),len(depths)))\n",
    "    hex_colors = [j.hex for j in colors]\n",
    "\n",
    "    colors = list(Color(\"red\").range_to(Color(\"yellow\"),len(depths)))\n",
    "    hex_colors_red = [j.hex for j in colors]\n",
    "\n",
    "    #     dist_centered = dist - single_front_locations[counter]\n",
    "\n",
    "    ax_mag = ax.twinx()\n",
    "\n",
    "    for idx_profs, z in enumerate(depths):\n",
    "        # cut it off at depth (dBars) >= z\n",
    "        df_tmp = profiles_subset[profiles_subset['depth (dBars)'] >= z] \n",
    "        df_tmp_grouped = df_tmp.groupby('profile_num').median()\n",
    "        df_tmp_grouped['datetime'] = pd.to_datetime('2021-1-1') + pd.to_timedelta(df_tmp_grouped.time, unit='D') - pd.Timedelta(days=1)\n",
    "        df_tmp_grouped = df_tmp_grouped.sort_values('dist')\n",
    "\n",
    "\n",
    "        ax.plot(df_tmp_grouped.dist,df_tmp_grouped['chla_adjusted']/df_tmp_grouped['chla_adjusted'].mean(), label='chla mean(0'+str(z)+')', color=hex_colors[idx_profs], ls='-')\n",
    "        ax.scatter(df_tmp_grouped.dist,df_tmp_grouped['chla_adjusted']/df_tmp_grouped['chla_adjusted'].mean(), color=hex_colors[idx_profs], ls='--')\n",
    "\n",
    "#         ax_mag.plot(df_tmp_grouped.dist,df_tmp_grouped['current_mag'], label='mag mean(0'+str(z)+')', color=hex_colors_red[idx_profs], ls='--')\n",
    "#         ax_mag.scatter(df_tmp_grouped.dist,df_tmp_grouped['current_mag'], color=hex_colors_red[idx_profs], ls='--')\n",
    "\n",
    "#         if idx_profs == 1:\n",
    "#             dudx = scipy.signal.savgol_filter(df_tmp_grouped['current_mag'], window_length=3, polyorder=2, deriv=1)\n",
    "#             front_location = np.argmax(np.abs(dudx))\n",
    "#             print(front_location)\n",
    "#             ax.axvline(df_tmp_grouped.dist[front_location],color='grey', ls='--')\n",
    "\n",
    "#     ax.set_ylim(-0.3,0.8)\n",
    "    ax.set_ylabel('chla')\n",
    "    \n",
    "    if idx not in [5,28,39,40,41]:\n",
    "        ax.set_xlim(dist.max(),0)\n",
    "    else:\n",
    "        ax.set_xlim(0,dist.max())\n",
    "\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #############################################\n",
    "\n",
    "    print('--------------------------------------')\n",
    "\n",
    "#     except Exception as e: \n",
    "#         print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just want to plot all of them together on the same figure centered at the front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_current_idxs = [68, 67, 66, 65, 64, 63, 59, 58, 56, 52, 51, 49, 48, 46, 45, 44, 43, 38, 34, 30, 22, 20, 17, 16, 13, 12, 10, 9, 8, 7, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gs_current_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_grouped.dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,1, figsize=(16,50))\n",
    "\n",
    "for idx,fn in enumerate(filenames):\n",
    "    if idx not in gs_current_idxs:\n",
    "        continue\n",
    "#     if idx != 64:\n",
    "#         continue\n",
    "    print(idx)\n",
    "    print(fn)\n",
    "    \n",
    "#     try:\n",
    "\n",
    "    dist = scipy.io.loadmat(fn+'_distance.mat')['distance']\n",
    "    sst = scipy.io.loadmat(fn+'_SST.mat')['SST']\n",
    "    time = scipy.io.loadmat(fn+'_time.mat')['time']\n",
    "    timestamps = pd.to_datetime(time[0,:]-719529, unit='D')\n",
    "\n",
    "    X = scipy.io.loadmat(fn+'_X.mat')['X']\n",
    "    Y = scipy.io.loadmat(fn+'_Y.mat')['Y']\n",
    "    vMag = scipy.io.loadmat(fn+'_vmag.mat')['C']\n",
    "\n",
    "    vDir = scipy.io.loadmat(fn+'_vdir.mat')['C']\n",
    "\n",
    "    echo = scipy.io.loadmat(fn+'_echo.mat')['C']\n",
    "    Xecho = scipy.io.loadmat(fn+'_Xecho.mat')['X']\n",
    "    Yecho = scipy.io.loadmat(fn+'_Yecho.mat')['Y']\n",
    "    # correcting for the smaller bin size\n",
    "    Yecho = (Yecho*0.502)-1\n",
    "\n",
    "    lat = scipy.io.loadmat(fn+'_lat.mat')['lat']\n",
    "    long = scipy.io.loadmat(fn+'_long.mat')['long']\n",
    "\n",
    "    # the distances are crazy wrong sometimes so re-calcuating the distance\n",
    "    coords_1 = (lat[0], long[0])\n",
    "    distances = []\n",
    "    for i in range(len(lat)):\n",
    "        coords_2 = (lat[i], long[i])\n",
    "        distances.append(distance.geodesic(coords_1, coords_2).meters)\n",
    "    dist = np.array(distances)       \n",
    "#         bogus_dist_locations = dist > 35000        \n",
    "#         dist[dist > 25000] = np.nan\n",
    "#         dist = pd.Series(dist).interpolate().values\n",
    "    # checking if the current point is within 500 of one that was good, assuming the first point is good\n",
    "    # then if not setting it to nan and interpolating it out\n",
    "    last_good_idx = 0\n",
    "    bad_idxs = []\n",
    "    for di,d in enumerate(dist):\n",
    "        if dist[di] - dist[last_good_idx] < 500:\n",
    "            last_good_idx = di\n",
    "        else:\n",
    "            bad_idxs.append(di)\n",
    "    dist[bad_idxs] = np.nan\n",
    "    dist = pd.Series(dist).interpolate().values\n",
    "\n",
    "    dist = dist.reshape(-1,1)\n",
    "    \n",
    "    adcp_df = pd.DataFrame({'dt':timestamps,\n",
    "                    'datetime':timestamps,\n",
    "                   'lat': lat[:,0],\n",
    "                   'lon':long[:,0],\n",
    "                           'dist':dist[:,0]})\n",
    "\n",
    "    adcp_df = adcp_df.set_index('dt')\n",
    "    adcp_df = adcp_df.sort_index(ascending=True)\n",
    "\n",
    "#     ax = plot_profiles(profiles, adcp_df, timestamps[0],timestamps[-1], ['potential density (kg/m^3 -1000)','temp (C)', 'salinity (PSU)', 'chla (ppb)'], plot=True)\n",
    "#     if idx not in [5,28,39,40,41]:\n",
    "#         for i in range(4):\n",
    "#             ax[i].set_xlim(dist.max(),0)    \n",
    "#     else:\n",
    "#         for i in range(4):\n",
    "#             ax[i].set_xlim(0,dist.max())\n",
    "#     for i in range(4):\n",
    "#         ax[i].set_ylim(-80,-1)\n",
    "# #             for sal_front in sal_front_location:\n",
    "# #                 ax[i].axvline(sal_front, c='k', ls='--')\n",
    "# #         plt.savefig('profiles'+str(idx)+'.png',dpi=300)\n",
    "#     plt.show()\n",
    "\n",
    "#     fig, ax = plt.subplots(1,1, figsize=(9.5,4))\n",
    "    vMag_reshape = vMag.reshape(-1,69).T\n",
    "    vDir_reshape = vDir.reshape(-1,69).T\n",
    "    \n",
    "#     x, y = np.meshgrid(dist,Y[:69,0])  \n",
    "#     im = ax.pcolormesh(x,y,vMag_reshape,shading='gouraud', vmin=0,vmax=250)\n",
    "#     fig.colorbar(im,ax=ax)\n",
    "#     ax.set_title(\"Current Magnitude (cm/s)\")\n",
    "\n",
    "    vgradient = []\n",
    "\n",
    "    N=180\n",
    "    current_speed = np.mean(vMag_reshape[0:4,:],axis=0)\n",
    "    current_speed_smooth = pd.Series(current_speed).rolling(window=N).mean().iloc[N-1:].values\n",
    "\n",
    "    step = 1\n",
    "\n",
    "    for i in range(len(current_speed)-N):\n",
    "        du = current_speed_smooth[i] - current_speed_smooth[i+step]\n",
    "        dx = dist[i] - dist[i+step]\n",
    "\n",
    "    dudx = scipy.signal.savgol_filter(current_speed_smooth, window_length=501, polyorder=2, deriv=1)\n",
    "\n",
    "#     ax_twin = ax.twinx()\n",
    "#     ax_twin.plot(dist[:-N+1], dudx, c='grey', ls='--')\n",
    "#     ax_twin.set_ylim(-0.6,0.6)\n",
    "\n",
    "#     ax_twin2 = ax.twinx()\n",
    "#     ax_twin2.plot(dist[:-N],current_speed_smooth[:-1],c='black')\n",
    "#     ax_twin2.set_ylim(0,250)\n",
    "\n",
    "#     ax_twin3 = ax.twinx()\n",
    "#     ax_twin3.plot(dist,sst, color='red')\n",
    "#     ax_twin3.set_ylim(18,30)\n",
    "#     # taking off the first 100 points because those are often noisy and never the front\n",
    "    front_location = np.argmax(np.abs(dudx[100:-30]))+100\n",
    "\n",
    "#     ax_twin.yaxis.label.set_color('grey')\n",
    "#     ax_twin.spines['right'].set_position(('outward', 90))\n",
    "\n",
    "#     ax_twin2.yaxis.label.set_color('black')\n",
    "#     ax_twin2.spines['right'].set_position(('outward', 180))\n",
    "\n",
    "#     ax_twin3.yaxis.label.set_color('red')\n",
    "#     ax_twin3.spines['right'].set_position(('outward', 260))\n",
    "\n",
    "#     ax_twin.set_ylabel('current gradient')\n",
    "#     ax_twin2.set_ylabel('top 10m current speed (cm/s)')\n",
    "#     ax_twin3.set_ylabel('SST (C)')\n",
    "\n",
    "\n",
    "#     if idx not in [5,28,39,40,41]:\n",
    "#         ax.set_xlim(dist.max(),0)\n",
    "#     else:\n",
    "#         ax.set_xlim(0,dist.max())\n",
    "#     ax.axvline(dist[front_location],color='k', ls='--')\n",
    "#     ax.set_ylim(-80,-2)\n",
    "#     ax.set_ylabel('Depth (m)')\n",
    "#     ax.set_xlabel('Dist from Start (m)')\n",
    "#     ax.axvline(dist[front_location],color='k', ls='--')\n",
    "\n",
    "\n",
    "#     fig.tight_layout()\n",
    "# #         fig.savefig('mag_dir_echo'+str(idx)+'.png',dpi=400)\n",
    "#     plt.show()\n",
    "    \n",
    "    ##################################\n",
    "    \n",
    "    \n",
    "    \n",
    "#     ax.axvline(dist[front_location],color='k', ls='--')\n",
    "\n",
    "\n",
    "    profiles_subset = profiles.loc[timestamps[0]:timestamps[-1]]\n",
    "\n",
    "    profiles_subset = profile_locs(profiles_subset, adcp_df)\n",
    "\n",
    "    #         integrate down to z depth\n",
    "    depths = [-10,-20,-30,-40,-60]\n",
    "\n",
    "    colors = list(Color(\"black\").range_to(Color(\"blue\"),len(depths)))\n",
    "    hex_colors = [j.hex for j in colors]\n",
    "\n",
    "    for idx_profs, z in enumerate(depths):\n",
    "        # cut it off at depth (dBars) >= z\n",
    "        df_tmp = profiles_subset[profiles_subset['depth (dBars)'] >= z] \n",
    "        df_tmp_grouped = df_tmp.groupby('profile_num').median()\n",
    "        df_tmp_grouped['datetime'] = pd.to_datetime('2021-1-1') + pd.to_timedelta(df_tmp_grouped.time, unit='D') - pd.Timedelta(days=1)\n",
    "        df_tmp_grouped = df_tmp_grouped.sort_values('dist')\n",
    "        \n",
    "        # here we're using the closest profile value to the front to normalize the transect \n",
    "        front_chla = df_tmp_grouped.iloc[(df_tmp_grouped['dist']-dist[front_location]).abs().argsort()[:1]]['chla_adjusted'].values\n",
    "\n",
    "        ax[idx_profs].plot(df_tmp_grouped.dist-dist[front_location],df_tmp_grouped['chla_adjusted']/df_tmp_grouped['chla_adjusted'][-1], label='chla mean(0'+str(z)+')', color=hex_colors[idx_profs], ls='-')\n",
    "        ax[idx_profs].scatter(df_tmp_grouped.dist-dist[front_location],df_tmp_grouped['chla_adjusted']/df_tmp_grouped['chla_adjusted'][-1], color=hex_colors[idx_profs], ls='--')\n",
    "        \n",
    "        ax[idx_profs].set_title(z)\n",
    "\n",
    "#         ax_mag.plot(df_tmp_grouped.dist,df_tmp_grouped['current_mag'], label='mag mean(0'+str(z)+')', color=hex_colors_red[idx_profs], ls='--')\n",
    "#         ax_mag.scatter(df_tmp_grouped.dist,df_tmp_grouped['current_mag'], color=hex_colors_red[idx_profs], ls='--')\n",
    "\n",
    "#         if idx_profs == 1:\n",
    "#             dudx = scipy.signal.savgol_filter(df_tmp_grouped['current_mag'], window_length=3, polyorder=2, deriv=1)\n",
    "#             front_location = np.argmax(np.abs(dudx))\n",
    "#             print(front_location)\n",
    "#             ax.axvline(df_tmp_grouped.dist[front_location],color='grey', ls='--')\n",
    "\n",
    "#     ax.set_ylim(-0.3,0.8)\n",
    "for i in range(5):\n",
    "    ax[i].axvline(0,color='grey', ls='--')\n",
    "    ax[i].set_ylabel('chla normalized to mean')\n",
    "    ax[i].set_xlim(7000,-7000)\n",
    "    ax[i].set_ylim(0.25,1.75)\n",
    "    # ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "plt.savefig('chla_across_front_normed_to_coastal_point.png',dpi=300)\n",
    "plt.show()\n",
    "    \n",
    "    #############################################\n",
    "\n",
    "\n",
    "#     except Exception as e: \n",
    "#         print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([d.timetuple().tm_yday for d in datetimes_subset],bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([d.timetuple().tm_yday for d in datetimes_subset],bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(10 * np.log10(16), 16 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_subset[profiles_subset['depth (dBars)'] > -8].groupby('profile_num').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(profiles_subset[profiles_subset['depth (dBars)'] > -8].groupby('profile_num').mean()['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(profiles_subset[profiles_subset['depth (dBars)'] > -8].groupby('profile_num').mean()['salinity (PSU)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sm.tsa.acf(profiles_subset[profiles_subset['depth (dBars)'] > -8].groupby('profile_num').mean()['salinity (PSU)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmag_for_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "depth_max = [0,-15,-25,-35]\n",
    "depth_min = [-10,-25,-35,-45]\n",
    "vars_for_calc = ['salinity (PSU)','temp (C)','chla (ppb)']\n",
    "\n",
    "for var_i, ax in enumerate([ax[0],ax[1],ax[2]]):\n",
    "    \n",
    "    var_for_cal = vars_for_calc[var_i]\n",
    "\n",
    "    ax2=ax.twinx()\n",
    "    ax.axhline(0,ls='--', c='k')\n",
    "    for depth_i in range(len(depth_max)):\n",
    "        input_df = profiles_subset[(profiles_subset['depth (dBars)'] < depth_max[depth_i]) & (profiles_subset['depth (dBars)'] > depth_min[depth_i])].groupby('profile_num').mean()\n",
    "        input_df = input_df.reindex(index=natsorted(input_df.index))\n",
    "        nlags = len(input_df)-1\n",
    "\n",
    "        ax2.plot(input_df['dist'],input_df[var_for_cal],label=var_for_cal+' '+str(depth_max[depth_i]) + ' to ' +str(depth_min[depth_i]),ls='--')\n",
    "        ax.plot(input_df['dist'],sm.tsa.acf(input_df[var_for_cal],nlags=nlags), label='autocorr '+var_for_cal+' '+str(depth_max[depth_i]) + ' to ' +str(depth_min[depth_i]))\n",
    "        ax.set_title(var_for_cal)\n",
    "        ax.legend(loc='lower left',bbox_to_anchor=(-0.1, -0.25))\n",
    "        ax2.legend(loc='lower right',bbox_to_anchor=(1.05, -0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vMag_reshape[:10,:].mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# input_df = profiles_subset[(profiles_subset['depth (dBars)'] < -15) & (profiles_subset['depth (dBars)'] > -25)].groupby('profile_num').mean()\n",
    "# input_df = input_df.reindex(index=natsorted(input_df.index))\n",
    "\n",
    "nlags = len(vMag_reshape[:20,100:].mean(axis=0))-1\n",
    "\n",
    "# var_for_cal = 'chla (ppb)'\n",
    "\n",
    "#calculate autocorrelations\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax2=ax.twinx()\n",
    "\n",
    "ax2.plot(x[0,100:],vMag_reshape[:20,100:].mean(axis=0), c='red')\n",
    "\n",
    "ax.plot(x[0,100:],sm.tsa.acf(vMag_reshape[:20,100:].mean(axis=0),nlags=nlags), c='k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosscorr(datax, datay, lag=0):\n",
    "    \"\"\" Lag-N cross correlation. \n",
    "    Parameters\n",
    "    ----------\n",
    "    lag : int, default 0\n",
    "    datax, datay : pandas.Series objects of equal length\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    crosscorr : float\n",
    "    \"\"\"\n",
    "    return datax.corr(datay.shift(lag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_subset.chla_clean.shift(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_subset.chla_clean.corr(profiles_subset.ekbackscatter.shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(profiles_subset.chla_clean, profiles_subset.ekbackscatter.shift(2),alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in p_sub.profile_num.unique():\n",
    "    plt.scatter(p_sub[p_sub.profile_num == p].chla_clean, p_sub[p_sub.profile_num == p].ekbackscatter.shift(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_subset[profiles_subset.profile_num == 't26_25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sub = profiles_subset[profiles_subset['depth (dBars)'] > -45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sub = profiles_subset[profiles_subset['depth (dBars)'] > -45]\n",
    "correls = []\n",
    "for p in p_sub.profile_num.unique():\n",
    "    correls.append([crosscorr(p_sub[p_sub.profile_num == p].chla_clean, p_sub[p_sub.profile_num == p].ekbackscatter, lag=i) for i in range(50)])\n",
    "plt.scatter([list(range(50))]*25,np.array(correls),alpha=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([list(range(50))]*25,np.array(correls),alpha=0.4)\n",
    "# plt.scatter(profiles_subset['depth (dBars)'].values[:50],np.nanmean(np.array(correls),axis=0)+np.nanstd(np.array(correls),axis=0))\n",
    "# plt.scatter(profiles_subset['depth (dBars)'].values[:50],np.nanmean(np.array(correls),axis=0)-np.nanstd(np.array(correls),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_subset.profile_num.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(profiles_subset['depth (dBars)'].values[:50],[crosscorr(profiles_subset.chla_clean, profiles_subset.ekbackscatter, lag=i) for i in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[crosscorr(profiles_subset.chla_clean, profiles_subset.ekbackscatter, lag=i) for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_transects, front_locations, time_starts, time_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_transects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in range(len(time_starts)):\n",
    "    dfs.append(profs_turb_sub.loc[time_starts[i]:time_stops[i]])\n",
    "profs_turb_frontal = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate the echosounder stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with three axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot violin plot on axes 1\n",
    "parts = ax.violinplot([np.concatenate(shelf_ek),np.concatenate(eddy_ek),np.concatenate(gulf_stream_ek)], positions=[0,1,2], quantiles=[[.25,.50,.75],[.25,.50,.75],[.25,.50,.75]])\n",
    "# ax1.set_title('Shelf')\n",
    "ax.set_ylim(92,125)\n",
    "\n",
    "cs = ['brown', 'yellow', 'blue']\n",
    "\n",
    "for i,pc in enumerate(parts['bodies']):\n",
    "    pc.set_facecolor(cs[i])\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(1)\n",
    "    \n",
    "for partname in ('cbars','cmins','cmaxes', 'cquantiles'):\n",
    "    vp = parts[partname]\n",
    "    vp.set_edgecolor('k')\n",
    "    vp.set_linewidth(1)\n",
    "    \n",
    "ax.set_xticks([0,1,2])\n",
    "ax.set_xticklabels(['Shelf', 'Eddy', 'Gulf Stream'])\n",
    "\n",
    "ax.set_title(\"Shelf, Eddy, GS Backscatter Strength\")\n",
    "ax.set_ylabel('Backscatter Strength (sV)')\n",
    "# plt.savefig('backscatter_strength.png',dpi=300)\n",
    "plt.show()\n",
    "\n",
    "np.concatenate(shelf_ek).mean(), np.concatenate(eddy_ek).mean(),np.concatenate(gulf_stream_ek).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs_turb_frontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# profiles_sub = profiles[profiles['depth (dBars)'] > -55]\n",
    "profiles_sub = profs_turb_frontal[profs_turb_frontal['depth (dBars)'] > -80]\n",
    "\n",
    "chla = profiles_sub['chla (ppb)'].values.copy()\n",
    "chla[chla > 2] = 2\n",
    "chla[chla < -0.3] = -0.3\n",
    "chla = chla + abs(chla.min())\n",
    "\n",
    "turbidity = profiles_sub['turbidity (FTU)'].values.copy()\n",
    "turbidity[turbidity > 4] = 4\n",
    "# turbidity = turbidity + abs(turbidity.min())\n",
    "\n",
    "\n",
    "# creating an object of LinearRegression class\n",
    "lr = LinearRegression()\n",
    "# fitting the training data\n",
    "X = np.array([profiles_sub['temp (C)'].values, profiles_sub['salinity (PSU)'].values, \n",
    "              profiles_sub['depth (dBars)'].values, abs(profiles_sub.datetime.dt.day_of_year.values-225)]).T\n",
    "y = chla\n",
    "\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(turbidity,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chla.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(chla,bins=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(profiles_sub.ekbackscatter,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(chla,profiles_sub.ekbackscatter,alpha=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chla.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(profiles_sub['depth (dBars)'],chla, alpha=0.01)\n",
    "plt.show()\n",
    "plt.scatter(profiles_sub['temp (C)'],chla, alpha=0.01)\n",
    "plt.show()\n",
    "plt.scatter(profiles_sub['salinity (PSU)'],chla, alpha=0.01)\n",
    "plt.show()\n",
    "plt.scatter(profiles_sub['potential density (kg/m^3 -1000)'],chla, alpha=0.01)\n",
    "plt.show()\n",
    "plt.scatter(turbidity,chla, alpha=0.01)\n",
    "plt.show()\n",
    "plt.scatter(abs(profiles_sub.datetime.dt.day_of_year.values-225),chla, alpha=0.01)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.scatter(chla, lr.predict(X), alpha=0.05)\n",
    "ax.set_xlim(0,2)\n",
    "ax.set_ylim(0,2)\n",
    "ax.set_ylabel('predicted')\n",
    "ax.set_xlabel('measured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(abs(profiles_sub.datetime.dt.day_of_year.values-225), profiles_sub['temp (C)'])\n",
    "plt.xlim(0,225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(profiles_sub['chla_clean'], profiles_sub['ekbackscatter'],alpha=0.3)\n",
    "# plt.xlim(0,225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(turbidity, chla,alpha=0.3)\n",
    "# plt.xlim(0,225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(turbidity)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(profiles_sub['temp (C)'], profiles_sub['salinity (PSU)'], profiles_sub['depth (dBars)'],c=chla, cmap='viridis',alpha=0.2,vmin=.0,vmax=1.5)\n",
    "ax.set_ylabel('Sal (PSU)')\n",
    "ax.set_xlabel('Temp (C)')\n",
    "ax.set_zlabel('Depth')\n",
    "fig.savefig('chla_across_TS_d.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(profiles_sub['temp (C)'], profiles_sub['salinity (PSU)'], abs(profiles_sub.datetime.dt.day_of_year.values-225),c=chla, cmap='viridis',alpha=0.2,vmin=.0,vmax=1.)\n",
    "\n",
    "ax.set_ylabel('Sal (PSU)')\n",
    "ax.set_xlabel('Temp (C)')\n",
    "ax.set_zlabel('Days from Aug 15')\n",
    "fig.savefig('chla_across_TS_DOY.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(abs(profiles_sub.datetime.dt.day_of_year.values-225), profiles_sub['temp (C)'], profiles_sub['depth (dBars)'],c=chla, cmap='viridis',alpha=0.5,vmin=.0,vmax=1.)\n",
    "\n",
    "ax.set_xlabel('Days from Aug 15')\n",
    "ax.set_ylabel('Temp (C)')\n",
    "ax.set_zlabel('Depth')\n",
    "fig.savefig('chla_across_t_s_d.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(abs(profiles_sub.datetime.dt.day_of_year.values-225), profiles_sub['temp (C)'], profiles_sub['depth (dBars)'],c=profiles_sub['ekbackscatter'], cmap='jet',alpha=0.5,vmin=101,vmax=109)\n",
    "\n",
    "ax.set_xlabel('Days from Aug 15')\n",
    "ax.set_ylabel('Temp (C)')\n",
    "ax.set_zlabel('Depth')\n",
    "# fig.savefig('eksv_across_t_s_d.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(profiles_sub['temp (C)'], profiles_sub['salinity (PSU)'], abs(profiles_sub.datetime.dt.day_of_year.values-225),c=profiles_sub['ekbackscatter'], cmap='jet',alpha=0.5,vmin=101,vmax=109)\n",
    "\n",
    "ax.set_ylabel('Sal (PSU)')\n",
    "ax.set_xlabel('Temp (C)')\n",
    "ax.set_zlabel('Days from Aug 15')\n",
    "# fig.savefig('eksv_across_TS_DOY.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,8))\n",
    "ax[0].scatter(profiles_sub['ekbackscatter'][profiles_sub['salinity (PSU)']>36], chla[profiles_sub['salinity (PSU)'] > 36] ,c= abs(profiles_sub.datetime.dt.day_of_year.values-225)[profiles_sub['salinity (PSU)']>36],alpha=.1)# cmap='jet',alpha=0.5,vmin=101,vmax=109)\n",
    "ax[0].set_xlim(93,125)\n",
    "\n",
    "ax[1].scatter(profiles_sub['ekbackscatter'][profiles_sub['salinity (PSU)']<36], chla[profiles_sub['salinity (PSU)'] < 36] ,c= abs(profiles_sub.datetime.dt.day_of_year.values-225)[profiles_sub['salinity (PSU)']<36],alpha=.1)# cmap='jet',alpha=0.5,vmin=101,vmax=109)\n",
    "ax[1].set_xlim(93,125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(profiles_sub['ekbackscatter'], chla , profiles_sub['salinity (PSU)'],c=abs(profiles_sub.datetime.dt.day_of_year.values-225))# cmap='jet',alpha=0.5,vmin=101,vmax=109)\n",
    "\n",
    "ax.set_ylabel('chla')\n",
    "ax.set_xlabel('acoustic backscatter')\n",
    "ax.set_zlabel('Days from Aug 15')\n",
    "# fig.savefig('eksv_across_TS_DOY.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(profiles_sub['temp (C)'], profiles_sub['salinity (PSU)'], profiles_sub['depth (dBars)'],c=profiles_sub['ekbackscatter'], cmap='jet',alpha=0.5,vmin=101,vmax=110)\n",
    "\n",
    "ax.set_ylabel('Sal (PSU)')\n",
    "ax.set_xlabel('Temp (C)')\n",
    "ax.set_zlabel('Depth')\n",
    "# fig.savefig('chla_across_TS_d.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(abs(profiles_sub.datetime.dt.day_of_year.values-225), profiles_sub['temp (C)'], profiles_sub['depth (dBars)'],c=turbidity, cmap=cmocean.cm.turbid,alpha=0.5,vmin=.95,vmax=1.7)\n",
    "\n",
    "ax.set_xlabel('Days from Aug 15')\n",
    "ax.set_ylabel('Temp (C)')\n",
    "ax.set_zlabel('Depth')\n",
    "# fig.savefig('turb_across_t_s_d.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(profiles_sub['temp (C)'], profiles_sub['salinity (PSU)'], abs(profiles_sub.datetime.dt.day_of_year.values-225),c=profiles_sub['turbidity (FTU)'], cmap=cmocean.cm.turbid,alpha=0.5,vmin=.95,vmax=1.7)\n",
    "\n",
    "ax.set_ylabel('Sal (PSU)')\n",
    "ax.set_xlabel('Temp (C)')\n",
    "ax.set_zlabel('Days from Aug 15')\n",
    "# fig.savefig('turb_across_t_s_d.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pygam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygam import PoissonGAM, s, te\n",
    "from pygam.datasets import chicago\n",
    "\n",
    "# X, y = chicago(return_X_y=True)\n",
    "\n",
    "gam = PoissonGAM(s(0, n_splines=10) + te(2, 3) + s(1)).fit(X, y)\n",
    "# gam = PoissonGAM(s(0) + s(1) + te(0, 3,n_splines=6)).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T, S, depth, DOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = gam.generate_X_grid(term=2, meshgrid=True)\n",
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "plt.ion()\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "XX = gam.generate_X_grid(term=1, meshgrid=True)\n",
    "Z = gam.partial_dependence(term=1, X=XX, meshgrid=True)\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(XX[0], XX[1], Z, cmap='viridis')\n",
    "ax.set_xlabel('Depth')\n",
    "ax.set_ylabel('DOY Dist from Summer')\n",
    "ax.set_zlabel('Chla Impact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygam import PoissonGAM, s, te\n",
    "from pygam.datasets import chicago\n",
    "\n",
    "# X, y = chicago(return_X_y=True)\n",
    "\n",
    "# gam = PoissonGAM(s(0, n_splines=10) + te(2, 3) + s(1)).fit(X, y)\n",
    "gam = PoissonGAM(s(0,n_splines=5) + s(1,n_splines=5) + te(0, 3,n_splines=5)).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "plt.ion()\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "XX = gam.generate_X_grid(term=2, meshgrid=True)\n",
    "Z = gam.partial_dependence(term=2, X=XX, meshgrid=True)\n",
    "# ax.plot(XX, gam.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(XX[0], XX[1], Z, cmap='viridis')\n",
    "ax.set_xlabel('T')\n",
    "ax.set_ylabel('DOY Dist from Summer')\n",
    "ax.set_zlabel('Chla Impact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['T', 'S']\n",
    "\n",
    "fig, axs = plt.subplots(1,len(titles),figsize=(20,6));\n",
    "for i, ax in enumerate(axs):\n",
    "    XX = gam.generate_X_grid(term=i)\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX))\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')\n",
    "#     ax.set_ylim(-2,2)\n",
    "    ax.set_title(titles[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygam import PoissonGAM, s, te, LinearGAM\n",
    "from pygam.datasets import chicago\n",
    "\n",
    "# X, y = chicago(return_X_y=True)\n",
    "\n",
    "gam = LinearGAM(s(0,n_splines=6) + s(1,n_splines=6) + s(2,n_splines=6) + s(3,n_splines=6)).fit(X, y)\n",
    "# gam = PoissonGAM(s(0) + s(1) + te(0, 1)).fit(X[:,3:], y)\n",
    "gam.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['T', 'S', 'depth', 'DOY']\n",
    "\n",
    "fig, axs = plt.subplots(1,len(titles),figsize=(20,6));\n",
    "for i, ax in enumerate(axs):\n",
    "    XX = gam.generate_X_grid(term=i)\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX))\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')\n",
    "#     ax.set_ylim(-2,2)\n",
    "    ax.set_title(titles[i]);\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a PCA plot with the variable vectors plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles[['depth (dBars)','temp (C)','salinity (PSU)','potential density (kg/m^3 -1000)','chla (ppb)','turbidity (FTU)','ekbackscatter','daysfromaug15']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(profiles[profiles['turbidity (FTU)']>3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles[profiles['turbidity (FTU)']>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(profiles[(profiles['turbidity (FTU)']<5) & (profiles['turbidity (FTU)']>2.5)]['turbidity (FTU)'],bins=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chla = profiles['chla (ppb)'].values.copy()\n",
    "chla[chla > 2] = 2\n",
    "chla[chla < -0.3] = -0.3\n",
    "chla = chla + abs(chla.min())\n",
    "\n",
    "profiles['chla_clean'] = chla\n",
    "\n",
    "###\n",
    "\n",
    "turbidity = profiles['turbidity (FTU)'].values.copy()\n",
    "turbidity[turbidity > 4] = 4\n",
    "\n",
    "profiles['turbidity_clean'] = turbidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs_turb_sub = profiles[profiles['turbidity (FTU)']<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles[profiles['chla (ppb)'] > 2]['chla (ppb)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(turbidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "pd.plotting.scatter_matrix(profiles_sub[['depth (dBars)','temp (C)','salinity (PSU)','potential density (kg/m^3 -1000)','chla_clean','turbidity_clean','daysfromaug15', 'cluster']], alpha=0.05,ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(profiles['turbidity_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(profiles['salinity (PSU)'] > profiles['gs_sal_thresh']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = profiles_sub[['temp (C)','salinity (PSU)','potential density (kg/m^3 -1000)','chla_clean','turbidity_clean']]\n",
    "\n",
    "#In general it is a good idea to scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "x_new = pca.transform(X)   \n",
    "\n",
    "labels = ['temp','salinity','potential density','chla','turbidity','daysfromaug15']\n",
    "\n",
    "def myplot(score,coeff,ax,labels,j):\n",
    "    xs = score[:,0]\n",
    "    ys = score[:,1]\n",
    "    n = coeff.shape[0]\n",
    "\n",
    "#     plt.scatter(xs ,ys, c = y,cmap='jet',alpha=.01,vmin=-80,vmax=0)#vmin=1.,vmax=1.5,alpha=0.1) #without scaling\n",
    "    if j == 0:\n",
    "#         im = ax.scatter(xs ,ys, color='darkgrey',alpha=0.01)#vmin=1.,vmax=1.5,alpha=0.1) #without scaling\n",
    "#         im = ax.scatter(xs ,ys, c = (profiles['salinity (PSU)'] > profiles['gs_sal_thresh']).astype(int),cmap='bwr',alpha=.01) #without scaling\n",
    "        im = ax.scatter(xs ,ys, c=profiles_sub['salinity (PSU)'],cmap=cmocean.cm.haline,alpha=.1,vmin=35,vmax=36.5) #without scaling\n",
    "        ax.set_title('Sal')\n",
    "    if j == 1:\n",
    "        im = ax.scatter(xs ,ys, c=profiles_sub['temp (C)'],cmap=cmocean.cm.thermal,alpha=.1) #without scaling\n",
    "        ax.set_title('Temp')\n",
    "        \n",
    "    if j == 2:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_sub['potential density (kg/m^3 -1000)'],cmap=cmocean.cm.dense,alpha=.2,vmin=21.2,vmax=27) #without scaling\n",
    "        ax.set_title('Density')\n",
    "        \n",
    "    elif j == 3:\n",
    "        im = ax.scatter(xs ,ys, c=profiles_sub['depth (dBars)'],cmap='cividis_r',alpha=.1,vmin=-80,vmax=0) #without scaling\n",
    "        ax.set_title('Depth')\n",
    "        \n",
    "    elif j == 4:\n",
    "        im = ax.scatter(xs ,ys, c=profiles_sub['daysfromaug15'],cmap=cmocean.cm.solar_r,alpha=.1,vmin=0,vmax=225) #without scaling\n",
    "        ax.set_title('Days from Aug 15')\n",
    "        \n",
    "    elif j == 5:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_sub['turbidity_clean'],cmap=cmocean.cm.turbid,alpha=.2,vmin=1.,vmax=1.8) #without scaling\n",
    "        ax.set_title('Turbidity')\n",
    "    elif j == 6:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_sub['chla_clean'],cmap=cmocean.cm.algae,alpha=.2,vmin=0.,vmax=1.5) #without scaling\n",
    "        ax.set_title('Chla Fluorescence')\n",
    "    elif j == 7:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_sub['ekbackscatter'],cmap='jet',alpha=.2,vmin=98,vmax=112) #without scaling\n",
    "        ax.set_title('EK Backscatter')\n",
    "    elif j == 8:\n",
    "#         im = ax.scatter(xs ,ys, c = (profiles['salinity (PSU)'] > profiles['gs_sal_thresh']).astype(int),cmap='bwr',alpha=.02) #without scaling\n",
    "          \n",
    "#         ax.set_title('GS (red) vs Coastal (blue)')\n",
    "    \n",
    "        im = ax.scatter(xs ,ys, c = profiles_sub.cluster  ,cmap='jet',alpha=.1,vmin=0,vmax=6) #without scaling\n",
    "        \n",
    "    fig.colorbar(im,ax=ax)\n",
    "    \n",
    "    for i in range(n):\n",
    "        ax.arrow(0, 0, coeff[i,0]*3, coeff[i,1]*3,color = 'r',alpha = 0.5, lw=2, head_width=.25,head_length=.25)\n",
    "        if labels is None:\n",
    "            ax.text(coeff[i,0]* 6, coeff[i,1] * 6, \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n",
    "        else:\n",
    "            ax.text(coeff[i,0]* 4, coeff[i,1] * 4, labels[i], color = 'black', ha = 'center', va = 'center')\n",
    "\n",
    "fig, ax = plt.subplots(3,3,figsize=(26,22))\n",
    "\n",
    "for i,ax in enumerate([ax[0,0],ax[0,1],ax[0,2],ax[1,0],ax[1,1],ax[1,2],ax[2,0],ax[2,1],ax[2,2]]):\n",
    "    ax.set_xlabel(\"PC{}\".format(1))\n",
    "    ax.set_ylabel(\"PC{}\".format(2))\n",
    "    ax.grid()\n",
    "    ax.set_xlim(-3,6.2)\n",
    "    ax.set_ylim(-3,6.5)\n",
    "\n",
    "    #Call the function. \n",
    "    myplot(x_new[:,0:2], pca.components_.T,ax=ax, labels=labels,j=i) \n",
    "fig.savefig('pca_profiles.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clust = OPTICS(min_samples=50, xi=0.05, min_cluster_size=0.05)\n",
    "\n",
    "# Run the fit\n",
    "clust.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(clust.labels_,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_200 = cluster_optics_dbscan(\n",
    "    reachability=clust.reachability_,\n",
    "    core_distances=clust.core_distances_,\n",
    "    ordering=clust.ordering_,\n",
    "    eps=.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.unique(labels_200,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "Sum_of_squared_distances = []\n",
    "K = range(1,15)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(X)\n",
    "    Sum_of_squared_distances.append(km.inertia_)\n",
    "    \n",
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 10,15]\n",
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_avg = []\n",
    "\n",
    "for num_clusters in range_n_clusters:\n",
    "    # initialise kmeans\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    kmeans.fit(X)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    # silhouette score\n",
    "    silhouette_avg.append(silhouette_score(X, cluster_labels,sample_size=10000))\n",
    "    print(num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range_n_clusters,silhouette_avg,'bx-')\n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Silhouette score') \n",
    "plt.title('Silhouette analysis For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = profs_turb_sub[['temp (C)','salinity (PSU)','potential density (kg/m^3 -1000)','chla_clean','turbidity_clean']]\n",
    "\n",
    "#In general it is a good idea to scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "\n",
    "kmeans = KMeans(n_clusters=7)\n",
    "kmeans.fit(X)\n",
    "cluster_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = profiles_gs[['depth (dBars)','temp (C)','salinity (PSU)','potential density (kg/m^3 -1000)','chla_clean','turbidity_clean','daysfromaug15']]\n",
    "\n",
    "#In general it is a good idea to scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "x_new = pca.transform(X)   \n",
    "\n",
    "labels = ['depth (dBars)','temp (C)','salinity (PSU)','potential density (kg/m^3 -1000)','chla (ppb)','turbidity (FTU)','daysfromaug15']\n",
    "\n",
    "def myplot(score,coeff,ax,labels,j):\n",
    "    xs = score[:,0]\n",
    "    ys = score[:,1]\n",
    "    n = coeff.shape[0]\n",
    "\n",
    "#     plt.scatter(xs ,ys, c = y,cmap='jet',alpha=.01,vmin=-80,vmax=0)#vmin=1.,vmax=1.5,alpha=0.1) #without scaling\n",
    "    if j == 0:\n",
    "        im = ax.scatter(xs ,ys, color='blue',alpha=0.02)#vmin=1.,vmax=1.5,alpha=0.1) #without scaling\n",
    "    elif j == 1:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_gs['chla_clean'],cmap=cmocean.cm.algae,alpha=.2,vmin=0.,vmax=1.5) #without scaling\n",
    "    elif j == 2:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_gs['ekbackscatter'],cmap='jet',alpha=.2,vmin=100.,vmax=112) #without scaling\n",
    "    elif j == 3:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_gs['turbidity_clean'],cmap=cmocean.cm.turbid,alpha=.2,vmin=1.,vmax=1.8) #without scaling\n",
    "    \n",
    "    fig.colorbar(im,ax=ax)\n",
    "    \n",
    "    for i in range(n):\n",
    "        ax.arrow(0, 0, coeff[i,0]*5, coeff[i,1]*5,color = 'r',alpha = 0.5, lw=2, head_width=.25,head_length=.25)\n",
    "        if labels is None:\n",
    "            ax.text(coeff[i,0]* 6, coeff[i,1] * 6, \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n",
    "        else:\n",
    "            ax.text(coeff[i,0]* 6.5, coeff[i,1] * 7, labels[i], color = 'black', ha = 'center', va = 'center')\n",
    "\n",
    "fig, ax = plt.subplots(2,2,figsize=(18,14))\n",
    "\n",
    "for i,ax in enumerate([ax[0,0],ax[0,1],ax[1,0],ax[1,1]]):\n",
    "    ax.set_xlabel(\"PC{}\".format(1))\n",
    "    ax.set_ylabel(\"PC{}\".format(2))\n",
    "    ax.grid()\n",
    "    ax.set_xlim(-4,5)\n",
    "    ax.set_ylim(-4,4)\n",
    "\n",
    "    #Call the function. \n",
    "    myplot(x_new[:,0:2], pca.components_.T,ax=ax, labels=labels,j=i) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "profiles_ek = profiles[profiles['ekbackscatter'].notna()]\n",
    "\n",
    "X = profiles_ek[['depth (dBars)','temp (C)','salinity (PSU)','potential density (kg/m^3 -1000)','chla_clean','turbidity_clean','daysfromaug15', 'ekbackscatter']]\n",
    "\n",
    "#In general it is a good idea to scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "x_new = pca.transform(X)   \n",
    "\n",
    "labels = ['depth','temp','salinity','potential density','chla','turbidity','daysfromaug15', 'ekbackscatter']\n",
    "\n",
    "def myplot(score,coeff,ax,labels,j):\n",
    "    xs = score[:,0]\n",
    "    ys = score[:,1]\n",
    "    n = coeff.shape[0]\n",
    "\n",
    "#     plt.scatter(xs ,ys, c = y,cmap='jet',alpha=.01,vmin=-80,vmax=0)#vmin=1.,vmax=1.5,alpha=0.1) #without scaling\n",
    "    if j == 0:\n",
    "#         im = ax.scatter(xs ,ys, color='darkgrey',alpha=0.01)#vmin=1.,vmax=1.5,alpha=0.1) #without scaling\n",
    "#         im = ax.scatter(xs ,ys, c = (profiles['salinity (PSU)'] > profiles['gs_sal_thresh']).astype(int),cmap='bwr',alpha=.01) #without scaling\n",
    "        im = ax.scatter(xs ,ys, c=profiles_ek['salinity (PSU)'],cmap=cmocean.cm.haline,alpha=.1,vmin=35,vmax=36.5) #without scaling\n",
    "        ax.set_title('Sal')\n",
    "    if j == 1:\n",
    "        im = ax.scatter(xs ,ys, c=profiles_ek['daysfromaug15'],cmap='cividis_r',alpha=.1,vmin=0,vmax=225) #without scaling\n",
    "        ax.set_title('Days from Aug 15')\n",
    "    if j == 2:\n",
    "        im = ax.scatter(xs ,ys, c=profiles_ek['temp (C)'],cmap=cmocean.cm.thermal,alpha=.1) #without scaling\n",
    "        ax.set_title('Temp')\n",
    "    elif j == 3:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_ek['chla_clean'],cmap=cmocean.cm.algae,alpha=.2,vmin=0.,vmax=1.5) #without scaling\n",
    "        ax.set_title('Chla Fluorescence')\n",
    "    elif j == 4:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_ek['turbidity_clean'],cmap=cmocean.cm.turbid,alpha=.2,vmin=1.,vmax=1.8) #without scaling\n",
    "        ax.set_title('Turbidity')\n",
    "    elif j == 5:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_ek['ekbackscatter'],cmap='jet',alpha=.2,vmin=100.,vmax=112) #without scaling\n",
    "        ax.set_title('EK Backscatter')\n",
    "    \n",
    "    fig.colorbar(im,ax=ax)\n",
    "    \n",
    "    for i in range(n):\n",
    "        ax.arrow(0, 0, coeff[i,0]*5, coeff[i,1]*5,color = 'r',alpha = 0.5, lw=2, head_width=.25,head_length=.25)\n",
    "        if labels is None:\n",
    "            ax.text(coeff[i,0]* 6, coeff[i,1] * 6, \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n",
    "        else:\n",
    "            ax.text(coeff[i,0]* 6.5, coeff[i,1] * 6.5, labels[i], color = 'black', ha = 'center', va = 'center')\n",
    "\n",
    "fig, ax = plt.subplots(3,2,figsize=(18,22))\n",
    "\n",
    "for i,ax in enumerate([ax[0,0],ax[0,1],ax[1,0],ax[1,1],ax[2,0],ax[2,1]]):\n",
    "    ax.set_xlabel(\"PC{}\".format(1))\n",
    "    ax.set_ylabel(\"PC{}\".format(2))\n",
    "    ax.grid()\n",
    "    ax.set_xlim(-4,5)\n",
    "    ax.set_ylim(-3,5)\n",
    "\n",
    "    #Call the function. \n",
    "    myplot(x_new[:,0:2], pca.components_.T,ax=ax, labels=labels,j=i) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = profiles_coastal[['depth (dBars)','temp (C)','salinity (PSU)','potential density (kg/m^3 -1000)','chla_clean','turbidity_clean','daysfromaug15']]\n",
    "\n",
    "#In general it is a good idea to scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "x_new = pca.transform(X)   \n",
    "\n",
    "labels = ['depth (dBars)','temp (C)','salinity (PSU)','potential density (kg/m^3 -1000)','chla (ppb)','turbidity (FTU)','daysfromaug15']\n",
    "\n",
    "def myplot(score,coeff,ax,labels,j):\n",
    "    xs = score[:,0]\n",
    "    ys = score[:,1]\n",
    "    n = coeff.shape[0]\n",
    "\n",
    "#     plt.scatter(xs ,ys, c = y,cmap='jet',alpha=.01,vmin=-80,vmax=0)#vmin=1.,vmax=1.5,alpha=0.1) #without scaling\n",
    "    if j == 0:\n",
    "        im = ax.scatter(xs ,ys, color='blue',alpha=0.02)#vmin=1.,vmax=1.5,alpha=0.1) #without scaling\n",
    "    elif j == 1:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_coastal['chla_clean'],cmap=cmocean.cm.algae,alpha=.2,vmin=0.,vmax=1.5) #without scaling\n",
    "    elif j == 2:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_coastal['ekbackscatter'],cmap='jet',alpha=.2,vmin=100.,vmax=112) #without scaling\n",
    "    elif j == 3:\n",
    "        im = ax.scatter(xs ,ys, c = profiles_coastal['turbidity_clean'],cmap=cmocean.cm.turbid,alpha=.2,vmin=1.,vmax=1.8) #without scaling\n",
    "    \n",
    "    fig.colorbar(im,ax=ax)\n",
    "    \n",
    "    for i in range(n):\n",
    "        ax.arrow(0, 0, coeff[i,0]*5, coeff[i,1]*5,color = 'r',alpha = 0.5, lw=2, head_width=.25,head_length=.25)\n",
    "        if labels is None:\n",
    "            ax.text(coeff[i,0]* 6, coeff[i,1] * 6, \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n",
    "        else:\n",
    "            ax.text(coeff[i,0]* 6.5, coeff[i,1] * 7, labels[i], color = 'black', ha = 'center', va = 'center')\n",
    "\n",
    "fig, ax = plt.subplots(2,2,figsize=(18,14))\n",
    "\n",
    "for i,ax in enumerate([ax[0,0],ax[0,1],ax[1,0],ax[1,1]]):\n",
    "    ax.set_xlabel(\"PC{}\".format(1))\n",
    "    ax.set_ylabel(\"PC{}\".format(2))\n",
    "    ax.grid()\n",
    "    ax.set_xlim(-4,5)\n",
    "    ax.set_ylim(-4,4)\n",
    "\n",
    "    #Call the function. \n",
    "    myplot(x_new[:,0:2], pca.components_.T,ax=ax, labels=labels,j=i) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = profiles[['depth (dBars)','temp (C)','salinity (PSU)','potential density (kg/m^3 -1000)','chla_clean','turbidity_clean','daysfromaug15']]\n",
    "\n",
    "y = profiles['chla_clean']\n",
    "\n",
    "#In general it is a good idea to scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "x_new = pca.transform(X)   \n",
    "\n",
    "labels = ['depth (dBars)','temp (C)','salinity (PSU)','potential density (kg/m^3 -1000)','chla (ppb)','turbidity (FTU)','daysfromaug15']\n",
    "\n",
    "def myplot(score,coeff,labels=labels):\n",
    "    xs = score[:,0]\n",
    "    ys = score[:,1]\n",
    "    n = coeff.shape[0]\n",
    "\n",
    "    plt.scatter(xs ,ys, c = y,cmap=cmocean.cm.algae,alpha=.2,vmin=0.,vmax=1.5) #without scaling\n",
    "    for i in range(n):\n",
    "        plt.arrow(0, 0, coeff[i,0]*5, coeff[i,1]*5,color = 'r',alpha = 0.5)\n",
    "        if labels is None:\n",
    "            plt.text(coeff[i,0]* 5, coeff[i,1] * 5, \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n",
    "        else:\n",
    "            plt.text(coeff[i,0]* 5, coeff[i,1] * 5, labels[i], color = 'black', ha = 'center', va = 'center')\n",
    "\n",
    "plt.xlabel(\"PC{}\".format(1))\n",
    "plt.ylabel(\"PC{}\".format(2))\n",
    "plt.grid()\n",
    "plt.ylim(-4,4)\n",
    "\n",
    "#Call the function. \n",
    "myplot(x_new[:,0:2], pca.components_.T) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(profiles['depth (dBars)'],profiles['temp (C)'],alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_front_locations = [f[0] for f in front_locations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now plot all the transects where the calculated front is 0 and the hot side is - and the cold side is +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = []\n",
    "front_location_list = []\n",
    "sst_list = []\n",
    "current_list = []\n",
    "echo_list = []\n",
    "interp_sst_list = []\n",
    "interp_current_list = []\n",
    "interp_echo_list = []\n",
    "\n",
    "sal_front_list = []\n",
    "\n",
    "vmp_sal_list = []\n",
    "vmp_temp_list = []\n",
    "vmp_chla_list = []\n",
    "vmp_dt_list = []\n",
    "\n",
    "grid_spacing = 20\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for idx,fn in enumerate(filenames):\n",
    "    if idx in [0,1,2,3]:\n",
    "        continue\n",
    "    if idx not in front_transects:\n",
    "        continue\n",
    "    try:\n",
    "        ##########\n",
    "        \n",
    "        dist = scipy.io.loadmat(fn+'_distance.mat')['distance']\n",
    "        sst = scipy.io.loadmat(fn+'_SST.mat')['SST']\n",
    "        time = scipy.io.loadmat(fn+'_time.mat')['time']\n",
    "        timestamps = pd.to_datetime(time[0,:]-719529, unit='D')\n",
    "       \n",
    "        \n",
    "#         if idx in [5,28,39,40,41]:\n",
    "#             dist = (dist - dist[-1])*-1\n",
    "        \n",
    "        X = scipy.io.loadmat(fn+'_X.mat')['X']\n",
    "        Y = scipy.io.loadmat(fn+'_Y.mat')['Y']\n",
    "        vMag = scipy.io.loadmat(fn+'_vmag.mat')['C']\n",
    "\n",
    "        vDir = scipy.io.loadmat(fn+'_vdir.mat')['C']\n",
    "        \n",
    "        vShear = scipy.io.loadmat(fn+'_vshear.mat')['C']\n",
    "        \n",
    "        echo = scipy.io.loadmat(fn+'_echo.mat')['C']\n",
    "        Xecho = scipy.io.loadmat(fn+'_Xecho.mat')['X']\n",
    "        Yecho = scipy.io.loadmat(fn+'_Yecho.mat')['Y']\n",
    "        \n",
    "        # correcting for the smaller bin size\n",
    "        Yecho = (Yecho*0.502)-1\n",
    "        \n",
    "        lat = scipy.io.loadmat(fn+'_lat.mat')['lat']\n",
    "        long = scipy.io.loadmat(fn+'_long.mat')['long']\n",
    "        \n",
    "        # the distances are crazy wrong sometimes so re-calcuating the distance\n",
    "        coords_1 = (lat[0], long[0])\n",
    "        distances = []\n",
    "        for i in range(len(lat)):\n",
    "            coords_2 = (lat[i], long[i])\n",
    "            distances.append(distance.geodesic(coords_1, coords_2).meters)\n",
    "        dist = np.array(distances)       \n",
    "#         bogus_dist_locations = dist > 35000        \n",
    "#         dist[dist > 25000] = np.nan\n",
    "#         dist = pd.Series(dist).interpolate().values\n",
    "        # checking if the current point is within 500 of one that was good, assuming the first point is good\n",
    "        # then if not setting it to nan and interpolating it out\n",
    "        last_good_idx = 0\n",
    "        bad_idxs = []\n",
    "        for di,d in enumerate(dist):\n",
    "            if dist[di] - dist[last_good_idx] < 500:\n",
    "                last_good_idx = di\n",
    "            else:\n",
    "                bad_idxs.append(di)\n",
    "        dist[bad_idxs] = np.nan\n",
    "        dist = pd.Series(dist).interpolate().values\n",
    "\n",
    "        dist = dist.reshape(-1,1)\n",
    "        \n",
    "        adcp_df = pd.DataFrame({'dt':timestamps,\n",
    "                    'datetime':timestamps,\n",
    "                    'sst':sst[:,0],\n",
    "                    'lat': lat[:,0],\n",
    "                    'lon':long[:,0],\n",
    "                    'dist':dist[:,0]})\n",
    "\n",
    "        adcp_df = adcp_df.set_index('dt')\n",
    "        adcp_df = adcp_df.sort_index(ascending=True)\n",
    "        \n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        sal_vmp, temp_vmp, chla_vmp, turb_vmp, dt_vmp, dist_vmp = grab_vmp_data(profiles, adcp_df, timestamps[0],timestamps[-1])\n",
    "            \n",
    "        vmp_sal_list.append(sal_vmp)\n",
    "        vmp_temp_list.append(temp_vmp)\n",
    "        vmp_chla_list.append(chla_vmp)\n",
    "        vmp_dt_list.append(dt_vmp)\n",
    "        \n",
    "        ################\n",
    "\n",
    "        \n",
    "        \n",
    "        if idx in [5,28,39,40,41]:\n",
    "            dist = (dist - dist[-1])*-1\n",
    "        \n",
    "\n",
    "        vMag_reshape = vMag.reshape(-1,69).T\n",
    "        vDir_reshape = vDir.reshape(-1,69).T\n",
    "        echo_reshape = echo.reshape(-1,127).T\n",
    "        echo_top_layer = np.mean(echo_reshape[0:8,:],axis=0)\n",
    "#         x, y = np.meshgrid(Xecho.reshape(-1,127)[:,0],Yecho[:127,0])    \n",
    "\n",
    "\n",
    "\n",
    "#         x, y = np.meshgrid(X.reshape(-1,69)[:,0],Y[:69,0])    \n",
    "\n",
    "        N=180\n",
    "        current_speed = np.mean(vMag_reshape[0:4,:],axis=0)\n",
    "        current_speed_smooth = pd.Series(current_speed).rolling(window=N).mean().iloc[N-1:].values\n",
    "        vgradient = []\n",
    "        step = 1\n",
    "\n",
    "        for i in range(len(current_speed)-N):\n",
    "            du = current_speed_smooth[i] - current_speed_smooth[i+step]\n",
    "            dx = dist[i] - dist[i+step]\n",
    "            current_grad = du/dx\n",
    "            vgradient.append(current_grad)\n",
    "\n",
    "        dudx = scipy.signal.savgol_filter(current_speed_smooth, window_length=11, polyorder=2, deriv=1)\n",
    "        # taking off the first 100 points because those are often noisy and never the front\n",
    "        front_location = np.argmax(np.abs(dudx[100:-30]))+100\n",
    "        \n",
    "        current_list.append(current_speed)\n",
    "        sst_list.append(sst)\n",
    "        dist_list.append(dist)\n",
    "        echo_list.append(echo_top_layer)\n",
    "        \n",
    "#         dist_centered = dist - dist[front_location]\n",
    "        dist_centered = dist - single_front_locations[counter]\n",
    "        counter += 1\n",
    "        \n",
    "        sst_reg = np.interp(np.arange(-12000,12000, grid_spacing), dist_centered[:,0], sst[:,0], left=np.nan, right=np.nan, period=None)\n",
    "        interp_sst_list.append(sst_reg)\n",
    "        \n",
    "        current_reg = np.interp(np.arange(-12000,12000, grid_spacing), dist_centered[:,0], current_speed, left=np.nan, right=np.nan, period=None)\n",
    "        interp_current_list.append(current_reg)\n",
    "        \n",
    "        dist_centered_echo = dist_centered[:,0]\n",
    "        while len(dist_centered_echo) != len(echo_top_layer):\n",
    "            \n",
    "            if len(dist_centered_echo) > len(echo_top_layer):\n",
    "                dist_centered_echo = dist_centered_echo[:-1]\n",
    "                \n",
    "            elif len(dist_centered[:,0]) < len(echo_top_layer):\n",
    "                echo_top_layer = echo_top_layer[:-1]\n",
    "\n",
    "        \n",
    "        echo_reg = np.interp(np.arange(-12000,12000, grid_spacing), dist_centered_echo, echo_top_layer, left=np.nan, right=np.nan, period=None)\n",
    "        interp_echo_list.append(echo_reg)\n",
    "        \n",
    "#         print('did one')\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_est = provide_gs_sal_threshold(np.concatenate(vmp_dt_list), buffer=0.25)\n",
    "gs_water = np.concatenate(vmp_sal_list) > sal_est\n",
    "\n",
    "\n",
    "temp_est = provide_gs_temp_threshold(np.concatenate(vmp_dt_list), buffer=0.25)\n",
    "gs_water_temp = np.concatenate(vmp_temp_list) > temp_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = []\n",
    "for i in range(len(gs_water)):\n",
    "    if gs_water[i] and not gs_water_temp[i]:\n",
    "        tester.append(True)\n",
    "    else:\n",
    "        tester.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = []\n",
    "for i in range(len(gs_water)):\n",
    "    if not gs_water[i] or not gs_water_temp[i]:\n",
    "        tester.append(False)\n",
    "    else:\n",
    "        tester.append(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want all the coastal water from both of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(temp_est-annual_temp_mean).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(profiles.datetime.dt.day_of_year,bins=52)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out boudaries (mins and maxs)\n",
    "smin = 32-.7\n",
    "smax = 37+.7\n",
    "tmin = 8-.7 \n",
    "tmax = 30+.7\n",
    "\n",
    "# Calculate how many gridcells we need in the x and y dimensions\n",
    "xdim = int(round((smax-smin)/0.1+1,0))\n",
    "ydim = int(round((tmax-tmin)+1,0))\n",
    " \n",
    "# Create empty grid of zeros\n",
    "dens = np.zeros((ydim,xdim))\n",
    " \n",
    "# Create temp and salt vectors of appropiate dimensions\n",
    "ti = np.linspace(1,ydim-1,ydim)+tmin\n",
    "si = np.linspace(1,xdim-1,xdim)*0.1+smin\n",
    " \n",
    "# Loop to fill in grid with densities\n",
    "for j in range(0,int(ydim)):\n",
    "    for i in range(0, int(xdim)):\n",
    "        dens[j,i]=gsw.rho(si[i],ti[j],0)\n",
    "\n",
    "# Substract 1000 to convert to sigma-t\n",
    "dens = dens - 1000\n",
    "    \n",
    "# plot T and S diagrams first with distance from coast and then with other variables\n",
    "fig, ax = plt.subplots(figsize=(8.5,7))\n",
    "markersize=40\n",
    "\n",
    "ax.set_xlim(32,37)\n",
    "ax.set_ylim(8,30)\n",
    "ax.set_xlabel('Salinity')\n",
    "ax.set_ylabel('Temperature (C)')\n",
    "\n",
    "CS = ax.contour(si,ti,dens, linestyles='dashed', colors='k', alpha=0.5)\n",
    "ax.clabel(CS, fontsize=12, inline=1, fmt='%1.1f') # Label every second level\n",
    "# ellipse = Ellipse(xy=(35.88, 28.05), width=0.5, height=1.2, angle=-20,\n",
    "#                 edgecolor='k', fc='None', ls='--', lw=2)\n",
    "# ax.add_patch(ellipse)\n",
    "\n",
    "# im = ax.scatter(np.concatenate(vmp_sal_list), np.concatenate(vmp_temp_list), c=np.concatenate(vmp_chla_list), vmin=-0.5,vmax=0.5,alpha=0.4)#c=np.concatenate(vmp_dt_list), vmin=0,vmax=365, cmap='twilight')\n",
    "\n",
    "temp_est = provide_gs_temp_threshold(np.concatenate(vmp_dt_list))\n",
    "sal_est = provide_gs_sal_threshold(np.concatenate(vmp_dt_list))\n",
    "\n",
    "im = ax.scatter(profiles[profiles['depth (dBars)'] < -35]['salinity (PSU)'], profiles[profiles['depth (dBars)'] < -35]['temp (C)'], c=profiles[profiles['depth (dBars)'] < -35].datetime.dt.day_of_year, cmap=cmocean.cm.phase, alpha=0.1)\n",
    "\n",
    "\n",
    "fig.colorbar(im)\n",
    "plt.show()\n",
    "\n",
    "# plot T and S diagrams first with distance from coast and then with other variables\n",
    "fig, ax = plt.subplots(figsize=(8.5,7))\n",
    "markersize=40\n",
    "\n",
    "ax.set_xlim(32,37)\n",
    "ax.set_ylim(8,30)\n",
    "ax.set_xlabel('Salinity')\n",
    "ax.set_ylabel('Temperature (C)')\n",
    "\n",
    "CS = ax.contour(si,ti,dens, linestyles='dashed', colors='k', alpha=0.5)\n",
    "ax.clabel(CS, fontsize=12, inline=1, fmt='%1.1f') # Label every second level\n",
    "# ellipse = Ellipse(xy=(35.88, 28.05), width=0.5, height=1.2, angle=-20,\n",
    "#                 edgecolor='k', fc='None', ls='--', lw=2)\n",
    "# ax.add_patch(ellipse)\n",
    "\n",
    "# im = ax.scatter(np.concatenate(vmp_sal_list), np.concatenate(vmp_temp_list), c=np.concatenate(vmp_chla_list), vmin=-0.5,vmax=0.5,alpha=0.4)#c=np.concatenate(vmp_dt_list), vmin=0,vmax=365, cmap='twilight')\n",
    "\n",
    "temp_est = provide_gs_temp_threshold(np.concatenate(vmp_dt_list))\n",
    "sal_est = provide_gs_sal_threshold(np.concatenate(vmp_dt_list))\n",
    "\n",
    "im = ax.scatter(profiles['salinity (PSU)'], profiles['temp (C)'], c=profiles['depth (dBars)'], cmap=cmocean.cm.deep_r, alpha=0.25, vmin=-100,vmax=0)\n",
    "\n",
    "\n",
    "fig.colorbar(im)\n",
    "plt.show()\n",
    "\n",
    "# plot T and S diagrams first with distance from coast and then with other variables\n",
    "fig, ax = plt.subplots(figsize=(8.5,7))\n",
    "markersize=40\n",
    "\n",
    "# ax.set_xlim(32,37)\n",
    "# ax.set_ylim(8,30)\n",
    "ax.set_xlabel('Salinity')\n",
    "ax.set_ylabel('Temperature (C)')\n",
    "\n",
    "CS = ax.contour(si,ti,dens, linestyles='dashed', colors='k', alpha=0.5)\n",
    "ax.clabel(CS, fontsize=12, inline=1, fmt='%1.1f') # Label every second level\n",
    "# ellipse = Ellipse(xy=(35.88, 28.05), width=0.5, height=1.2, angle=-20,\n",
    "#                 edgecolor='k', fc='None', ls='--', lw=2)\n",
    "# ax.add_patch(ellipse)\n",
    "\n",
    "# im = ax.scatter(np.concatenate(vmp_sal_list), np.concatenate(vmp_temp_list), c=np.concatenate(vmp_chla_list), vmin=-0.5,vmax=0.5,alpha=0.4)#c=np.concatenate(vmp_dt_list), vmin=0,vmax=365, cmap='twilight')\n",
    "\n",
    "temp_est = provide_gs_temp_threshold(np.concatenate(vmp_dt_list))\n",
    "sal_est = provide_gs_sal_threshold(np.concatenate(vmp_dt_list))\n",
    "\n",
    "depth = -50\n",
    "\n",
    "im = ax.scatter(profiles[profiles['depth (dBars)'] < depth]['salinity (PSU)'], profiles[profiles['depth (dBars)'] < depth]['temp (C)'], c=profiles[profiles['depth (dBars)'] < depth]['depth (dBars)'], cmap=cmocean.cm.deep_r, alpha=0.25, vmin=-100,vmax=depth)\n",
    "\n",
    "\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = []\n",
    "for i in gs_water.astype(np.int):\n",
    "    if i == 0:\n",
    "        markers.append('^')\n",
    "    else:\n",
    "        markers.append('o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out boudaries (mins and maxs)\n",
    "smin = 32-.7\n",
    "smax = 37+.7\n",
    "tmin = 8-.7 \n",
    "tmax = 30+.7\n",
    "\n",
    "# Calculate how many gridcells we need in the x and y dimensions\n",
    "xdim = int(round((smax-smin)/0.1+1,0))\n",
    "ydim = int(round((tmax-tmin)+1,0))\n",
    " \n",
    "# Create empty grid of zeros\n",
    "dens = np.zeros((ydim,xdim))\n",
    " \n",
    "# Create temp and salt vectors of appropiate dimensions\n",
    "ti = np.linspace(1,ydim-1,ydim)+tmin\n",
    "si = np.linspace(1,xdim-1,xdim)*0.1+smin\n",
    " \n",
    "# Loop to fill in grid with densities\n",
    "for j in range(0,int(ydim)):\n",
    "    for i in range(0, int(xdim)):\n",
    "        dens[j,i]=gsw.rho(si[i],ti[j],0)\n",
    "\n",
    "# Substract 1000 to convert to sigma-t\n",
    "dens = dens - 1000\n",
    "\n",
    "\n",
    "    \n",
    "# plot T and S diagrams first with distance from coast and then with other variables\n",
    "fig, ax = plt.subplots(figsize=(8.5,7))\n",
    "markersize=40\n",
    "\n",
    "ax.set_xlim(32,37)\n",
    "ax.set_ylim(8,30)\n",
    "ax.set_xlabel('Salinity')\n",
    "ax.set_ylabel('Temperature (C)')\n",
    "\n",
    "CS = ax.contour(si,ti,dens, linestyles='dashed', colors='k', alpha=0.5)\n",
    "ax.clabel(CS, fontsize=12, inline=1, fmt='%1.1f') # Label every second level\n",
    "# ellipse = Ellipse(xy=(35.88, 28.05), width=0.5, height=1.2, angle=-20,\n",
    "#                 edgecolor='k', fc='None', ls='--', lw=2)\n",
    "# ax.add_patch(ellipse)\n",
    "\n",
    "# im = ax.scatter(np.concatenate(vmp_sal_list), np.concatenate(vmp_temp_list), c=np.concatenate(vmp_chla_list), vmin=-0.5,vmax=0.5,alpha=0.4)#c=np.concatenate(vmp_dt_list), vmin=0,vmax=365, cmap='twilight')\n",
    "\n",
    "temp_est = provide_gs_temp_threshold(np.concatenate(vmp_dt_list))\n",
    "sal_est = provide_gs_sal_threshold(np.concatenate(vmp_dt_list))\n",
    "\n",
    "im = ax.scatter(np.concatenate(vmp_sal_list)-(sal_est-annual_sal_mean), np.concatenate(vmp_temp_list)-(temp_est-annual_temp_mean),c=gs_water.astype(np.int), cmap='bwr',)\n",
    "\n",
    "\n",
    "fig.colorbar(im)\n",
    "ax.set_title(\"Normalized S and T\")\n",
    "fig.savefig('normed_ts_diagram_allprofiles.png',dpi=300)\n",
    "    \n",
    "# ax.legend()\n",
    "# fig.savefig('figs/simple_t_s_diagram_all_transects_with_divisions.png',dpi=300)\n",
    "\n",
    "# plot T and S diagrams first with distance from coast and then with other variables\n",
    "fig, ax = plt.subplots(figsize=(8.5,7))\n",
    "markersize=40\n",
    "\n",
    "ax.set_xlim(32,37)\n",
    "ax.set_ylim(8,30)\n",
    "ax.set_xlabel('Salinity')\n",
    "ax.set_ylabel('Temperature (C)')\n",
    "\n",
    "CS = ax.contour(si,ti,dens, linestyles='dashed', colors='k', alpha=0.5)\n",
    "ax.clabel(CS, fontsize=12, inline=1, fmt='%1.1f') # Label every second level\n",
    "# ellipse = Ellipse(xy=(35.88, 28.05), width=0.5, height=1.2, angle=-20,\n",
    "#                 edgecolor='k', fc='None', ls='--', lw=2)\n",
    "# ax.add_patch(ellipse)\n",
    "\n",
    "# im = ax.scatter(np.concatenate(vmp_sal_list), np.concatenate(vmp_temp_list), c=abs(np.concatenate(vmp_dt_list)-225), vmin=0,vmax=225, cmap=cmocean.cm.ice,alpha=0.4)\n",
    "im = ax.scatter(np.concatenate(vmp_sal_list)[gs_water.astype(np.int) ==1], np.concatenate(vmp_temp_list)[gs_water.astype(np.int) ==1], c=abs(np.concatenate(vmp_dt_list)-225)[gs_water.astype(np.int) ==1], cmap='jet', marker='x',vmin=0,vmax=225)\n",
    "im = ax.scatter(np.concatenate(vmp_sal_list)[gs_water.astype(np.int) ==0], np.concatenate(vmp_temp_list)[gs_water.astype(np.int) ==0], c=abs(np.concatenate(vmp_dt_list)-225)[gs_water.astype(np.int) ==0], cmap='jet', marker='^',vmin=0,vmax=225)\n",
    "fig.colorbar(im)\n",
    "ax.set_title(\"Raw S and T\")\n",
    "fig.savefig('ts_diagram_allprofiles_DOY.png',dpi=300)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D view of T-S diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.concatenate(vmp_chla_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(np.concatenate(vmp_temp_list), np.concatenate(vmp_sal_list), abs(np.concatenate(vmp_dt_list)-225),c=gs_water.astype(np.int), cmap='bwr')\n",
    "\n",
    "ax.set_ylabel('Sal (PSU)')\n",
    "ax.set_xlabel('Temp (C)')\n",
    "ax.set_zlabel('Days from Aug 15')\n",
    "# fig.savefig('chla_across_TS_DOY.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at ek backscatter seasonality in the GS water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['gs_sal_thresh'] = provide_gs_sal_threshold(profiles['daysfromaug15'], buffer=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['daysfromaug15'] = abs(profiles.datetime.dt.dayofyear-225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_gs = profiles[profiles['salinity (PSU)'] > profiles['gs_sal_thresh']]\n",
    "profiles_coastal = profiles[profiles['salinity (PSU)'] < profiles['gs_sal_thresh']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(profiles[profiles['depth (dBars)'] > -35]['daysfromaug15'], profiles[profiles['depth (dBars)'] > -35]['ekbackscatter'], c=profiles[profiles['depth (dBars)'] > -35]['temp (C)'],cmap=cmocean.cm.thermal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(profiles_gs[profiles_gs['depth (dBars)'] > -35]['chla (ppb)'],bins=500)\n",
    "plt.xlim(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = -45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_gs.groupby('daysfromaug15').mean().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(profiles_gs[profiles_gs['depth (dBars)'] > depth].groupby('daysfromaug15').mean().index, profiles_gs[profiles_gs['depth (dBars)'] > depth].groupby('daysfromaug15').mean()['chla (ppb)'], \n",
    "            c=profiles_gs[profiles_gs['depth (dBars)'] > depth].groupby('daysfromaug15').mean()['chla (ppb)'],vmin=-.5,vmax=.8,cmap=cmocean.cm.algae)\n",
    "plt.ylim(-.25,.5)\n",
    "plt.xlim(0,225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(profiles_gs[profiles_gs['depth (dBars)'] > depth].groupby('daysfromaug15').mean().index, profiles_gs[profiles_gs['depth (dBars)'] > depth].groupby('daysfromaug15').mean()['ekbackscatter'], \n",
    "            c=profiles_gs[profiles_gs['depth (dBars)'] > depth].groupby('daysfromaug15').mean()['chla (ppb)'],vmin=-.5,vmax=.8,cmap=cmocean.cm.algae)\n",
    "plt.xlim(0,225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(profiles_coastal[profiles_coastal['depth (dBars)'] > depth]['daysfromaug15'], profiles_coastal[profiles_coastal['depth (dBars)'] > depth]['ekbackscatter'], c=profiles_coastal[profiles_coastal['depth (dBars)'] > depth]['chla (ppb)'],vmin=-.5,vmax=.8,cmap=cmocean.cm.algae)\n",
    "plt.xlim(0,225)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the S and T GS Frontal division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = np.array(tester)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot just the gs water trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_water\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "im = ax.scatter(abs(np.concatenate(vmp_dt_list)-225)[~tester],vmp_chla_clean[~tester], c=np.concatenate(vmp_sal_list)[~tester], cmap=cmocean.cm.haline,facecolors='none',)\n",
    "fig.colorbar(im)\n",
    "# abs(np.concatenate(vmp_dt_list) -180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_water\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "im = ax.scatter(abs(np.concatenate(vmp_dt_list)-225)[gs_water],vmp_chla_clean[gs_water], facecolors='none',)#c=np.concatenate(vmp_temp_list)[gs_water], cmap=cmocean.cm.thermal)\n",
    "fig.colorbar(im)\n",
    "# abs(np.concatenate(vmp_dt_list) -180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_water\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "im = ax.scatter(np.concatenate(vmp_temp_list)[gs_water],np.concatenate(vmp_sal_list)[gs_water], c=vmp_chla_clean[gs_water], cmap=cmocean.cm.algae, vmin=-0.25,vmax=0.25)\n",
    "fig.colorbar(im)\n",
    "# abs(np.concatenate(vmp_dt_list) -180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_water\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "im = ax.scatter(np.concatenate(vmp_temp_list)[~gs_water],vmp_chla_clean[~gs_water], c=vmp_chla_clean[~gs_water], cmap=cmocean.cm.algae, vmin=-0.25,vmax=0.25)\n",
    "fig.colorbar(im)\n",
    "# abs(np.concatenate(vmp_dt_list) -180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_water\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "im = ax.scatter(np.concatenate(vmp_sal_list)[~gs_water],vmp_chla_clean[~gs_water], c=np.concatenate(vmp_temp_list)[~gs_water], cmap=cmocean.cm.algae)\n",
    "fig.colorbar(im)\n",
    "# abs(np.concatenate(vmp_dt_list) -180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "im = ax.scatter(abs(np.concatenate(vmp_dt_list)-225),vmp_chla_clean, c=np.concatenate(vmp_sal_list), cmap=cmocean.cm.haline)\n",
    "fig.colorbar(im)\n",
    "# abs(np.concatenate(vmp_dt_list) -180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# im = ax.scatter(abs(dates_x_sst-225),sst_mean.gs_sst-273, c=dates_x_sst)\n",
    "temp_est = provide_gs_temp_threshold(dates_x_sst)\n",
    "im = ax.scatter(dates_x_sst,sst_mean.gs_sst-273-temp_est, c=dates_x_sst)\n",
    "\n",
    "fig.colorbar(im)\n",
    "# abs(np.concatenate(vmp_dt_list) -180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "im = ax.scatter(np.concatenate(vmp_sal_list), np.concatenate(vmp_temp_list), c=np.concatenate(vmp_chla_list), vmin=-0.5,vmax=0.5)\n",
    "fig.colorbar(im)\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "im = ax.scatter(np.concatenate(vmp_sal_list), np.concatenate(vmp_temp_list), c=np.concatenate(vmp_dt_list), vmin=0,vmax=365, cmap='twilight')\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_sst_list = np.array(interp_sst_list)\n",
    "interp_current_list = np.array(interp_current_list)\n",
    "interp_echo_list = np.array(interp_echo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetimes = [datetime.strptime(f.split('_')[2][4:-5], '%m%dT%H%S') for f in filenames]\n",
    "\n",
    "datetimes = [datetime.strptime(f.split('_')[2][:-5], '%Y%m%dT%H%S') for f in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes_subset = [datetimes[i] for i in tentative_good_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes_subset = [datetimes[i] for i in front_transects[:32]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datetimes_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,len(datetimes_subset),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(interp_echo_list,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, x in enumerate(sal_front_list):\n",
    "    if len(x) > 0:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 3\n",
    "ncols = 5\n",
    "Z = np.nan_to_num(interp_echo_list,0)\n",
    "x = np.arange(1200 + 1)\n",
    "y = np.arange(49 + 1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(x, datetimes_subset, Z, shading='none', vmin=Z.min(), vmax=Z.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(interp_current_list.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,9))\n",
    "z = np.nan_to_num(interp_current_list,0)\n",
    "z = np.ma.masked_array(z, z < 1)\n",
    "# ax.pcolormesh(x, datetimes_subset, z, cmap='viridis',vmin=0,vmax=250)\n",
    "im = ax.pcolormesh(z, cmap='bwr',vmin=0,vmax=200)\n",
    "fig.colorbar(im)\n",
    "\n",
    "ax.axvline(600,c='k',ls='--')\n",
    "ax.set_yticklabels([])\n",
    "for i in range(len(datetimes_subset)):\n",
    "    ax.text(-130, i, datetimes_subset[i].strftime(\"%d - %m - %y\"))\n",
    "    \n",
    "ax.set_xlabel('Dekameters (front is located at 600 dm)')\n",
    "    \n",
    "# plt.savefig('surface_current_speed_front_adcp.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(interp_sst_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datetimes_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,9))\n",
    "z = np.nan_to_num(interp_sst_list,0)\n",
    "z = np.ma.masked_array(z, z < 1)\n",
    "im = ax.pcolormesh(z, cmap='inferno',vmin=12,vmax=30)\n",
    "fig.colorbar(im)\n",
    "\n",
    "ax.axvline(600,c='k',ls='--')\n",
    "ax.set_yticklabels([])\n",
    "for i in range(len(datetimes_subset)):\n",
    "    ax.text(-130, i, datetimes_subset[i].strftime(\"%d - %m - %y\"))\n",
    "    \n",
    "ax.set_xlabel('Dekameters (front is located at 600 dm)')\n",
    "        \n",
    "# plt.savefig('surface_sst_front_adcp.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(interp_echo_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "# a Gaussian filter with a standard deviation of 10\n",
    "[ndimage.gaussian_filter1d(line, 10) for line in interp_echo_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,9))\n",
    "z = np.nan_to_num([ndimage.gaussian_filter1d(line, 5) for line in interp_echo_list],0)\n",
    "z = np.ma.masked_array(z, z < 1)\n",
    "ax.pcolormesh(z, cmap='jet',vmin=95,vmax=120)\n",
    "\n",
    "ax.axvline(600,c='k',alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "ax.scatter(datetimes_subset,np.nanmean(interp_echo_list[:,450:600],axis=1),c='red',label='Hot Side')\n",
    "ax.scatter(datetimes_subset,np.nanmean(interp_echo_list[:,750:900],axis=1),c='blue',label='Cold Side')\n",
    "ax.legend()\n",
    "ax.set_ylabel('Backscatter (sV)')\n",
    "ax.set_xlabel('Date')\n",
    "\n",
    "ax.set_title('Backscatter from top 10m')\n",
    "fig.autofmt_xdate(bottom=0.2, rotation=30, ha='right')\n",
    "\n",
    "# plt.savefig('echo_response_full_dataset.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "ax.scatter(datetimes_subset,np.nanmean(interp_sst_list[:,450:600],axis=1),c='red')\n",
    "ax.scatter(datetimes_subset,np.nanmean(interp_sst_list[:,600:750],axis=1),c='blue')\n",
    "\n",
    "ax.set_ylabel('SST (C)')\n",
    "ax.set_xlabel('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "ax.scatter(datetimes_subset,np.nanmean(interp_current_list[:,450:600],axis=1),c='red')\n",
    "ax.scatter(datetimes_subset,np.nanmean(interp_current_list[:,600:750],axis=1),c='blue')\n",
    "\n",
    "ax.set_ylabel('current speed (cm/s)')\n",
    "ax.set_xlabel('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "ax.scatter(datetimes_subset,np.nanmean(interp_current_list[:,450:600]-interp_current_list[:,600:750],axis=1),c='red')\n",
    "# ax.scatter(datetimes_subset,np.nanmean(interp_current_list[:,600:750],axis=1),c='blue')\n",
    "\n",
    "ax.set_ylabel('current speed (cm/s)')\n",
    "ax.set_xlabel('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an array with x as distance and y as sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "\n",
    "# for i in range(len(dist_list)):\n",
    "for i in range(10):\n",
    "    dist = dist_list[i]\n",
    "    echo = echo_list[i]\n",
    "    front_location = front_location_list[i]\n",
    "    echo_reg = interp_echo_list[i]\n",
    "    \n",
    "    dist_centered = dist - dist[front_location]\n",
    "    ax.plot(np.arange(-12000,12000, grid_spacing),echo_reg,alpha=0.3)\n",
    "    \n",
    "# ax.plot(np.arange(-12000,12000, grid_spacing),np.nanmean(interp_echo_list,axis=0), color='black',alpha=1, lw=3, label='mean echo')\n",
    "# ax.plot(np.arange(-12000,12000, grid_spacing),np.nanstd(interp_echo_list,axis=0)+np.nanmean(interp_echo_list,axis=0), color='black',alpha=.5, lw=2,label='std deviation')\n",
    "# ax.plot(np.arange(-12000,12000, grid_spacing),np.nanmean(interp_echo_list,axis=0)-np.nanstd(interp_echo_list,axis=0), color='black',alpha=.5, lw=2)\n",
    "\n",
    "ax.set_ylabel('echo (sV)')\n",
    "ax.set_xlabel('distance from front (m, negative is offshore)')\n",
    "\n",
    "\n",
    "ax.axvline(0,c='k',ls='--')\n",
    "ax.set_xlim(-6000,6000)\n",
    "\n",
    "# fig.savefig('adcp_sst_across_front.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "\n",
    "for i in range(len(dist_list)):\n",
    "    dist = dist_list[i]\n",
    "    sst = sst_list[i]\n",
    "    front_location = front_location_list[i]\n",
    "    sst_reg = interp_sst_list[i]\n",
    "    \n",
    "    dist_centered = dist - dist[front_location]\n",
    "    ax.plot(np.arange(-12000,12000, grid_spacing),sst_reg,alpha=0.3)\n",
    "    \n",
    "ax.plot(np.arange(-12000,12000, grid_spacing),np.nanmean(interp_sst_list,axis=0), color='black',alpha=1, lw=3, label='mean SST')\n",
    "ax.plot(np.arange(-12000,12000, grid_spacing),np.nanstd(interp_sst_list,axis=0)+np.nanmean(interp_sst_list,axis=0), color='black',alpha=.5, lw=2,label='std deviation')\n",
    "ax.plot(np.arange(-12000,12000, grid_spacing),np.nanmean(interp_sst_list,axis=0)-np.nanstd(interp_sst_list,axis=0), color='black',alpha=.5, lw=2)\n",
    "\n",
    "ax.set_ylabel('SST (C)')\n",
    "ax.set_xlabel('distance from front (m, negative is offshore)')\n",
    "\n",
    "\n",
    "ax.axvline(0,c='k',ls='--')\n",
    "ax.set_xlim(-6000,6000)\n",
    "\n",
    "# fig.savefig('adcp_sst_across_front.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_reg[600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "\n",
    "for i in range(len(dist_list)):\n",
    "    dist = dist_list[i]\n",
    "    sst = sst_list[i]\n",
    "    front_location = front_location_list[i]\n",
    "    current_reg = interp_current_list[i]\n",
    "    \n",
    "    dist_centered = dist - dist[front_location]\n",
    "    ax.plot(np.arange(-12000,12000, grid_spacing),current_reg,alpha=0.2)\n",
    "    \n",
    "ax.plot(np.arange(-12000,12000, grid_spacing),np.nanmean(interp_current_list,axis=0), color='black',alpha=1, lw=3, label='mean current')\n",
    "ax.plot(np.arange(-12000,12000, grid_spacing),np.nanstd(interp_current_list,axis=0)+np.nanmean(interp_current_list,axis=0), color='black',alpha=.5, lw=2, label='std deviation')\n",
    "ax.plot(np.arange(-12000,12000, grid_spacing),np.nanmean(interp_current_list,axis=0)-np.nanstd(interp_current_list,axis=0), color='black',alpha=.5, lw=2)\n",
    "\n",
    "ax.set_ylabel('current speed (m/s)')\n",
    "ax.set_xlabel('distance from front (m, negative is offshore)')\n",
    "\n",
    "ax.legend()\n",
    "ax.axvline(0,c='k',ls='--')\n",
    "ax.set_xlim(-6000,6000)\n",
    "# fig.savefig('adcp_current_speed_across_front.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "\n",
    "for i in range(len(dist_list)):\n",
    "    dist = dist_list[i]\n",
    "    sst = sst_list[i]\n",
    "    front_location = front_location_list[i]\n",
    "    \n",
    "    dist_centered = dist - dist[front_location]\n",
    "    ax.plot(dist_centered,sst,alpha=0.5)\n",
    "ax.axvline(0,c='k',ls='--')\n",
    "ax.set_xlim(-6000,6000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "\n",
    "for i in range(len(dist_list)):\n",
    "    dist = dist_list[i]\n",
    "    sst = sst_list[i]\n",
    "    front_location = front_location_list[i]\n",
    "    \n",
    "    dist_centered = dist - dist[front_location]\n",
    "    ax.plot(dist_centered,sst/sst[front_location],alpha=0.5)\n",
    "ax.set_xlim(-6000,6000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "\n",
    "for i in range(len(dist_list)):\n",
    "    dist = dist_list[i]\n",
    "    sst = sst_list[i]\n",
    "    front_location = front_location_list[i]\n",
    "    \n",
    "    dist_centered = dist - dist[front_location]\n",
    "    ax.plot(dist_centered,sst/sst[front_location],alpha=0.5)\n",
    "ax.set_xlim(-6000,6000)\n",
    "ax.set_ylim(.8,1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "\n",
    "for i in range(len(dist_list)):\n",
    "    dist = dist_list[i]\n",
    "    current = current_list[i]\n",
    "    front_location = front_location_list[i]\n",
    "    \n",
    "    dist_centered = dist - dist[front_location]\n",
    "    ax.plot(dist_centered,current/current[front_location],alpha=0.5)\n",
    "ax.axvline(0,c='k',ls='--')\n",
    "ax.set_xlim(-6000,6000)\n",
    "ax.set_ylim(0,2.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
